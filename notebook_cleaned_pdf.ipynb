{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random_state = 12041500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_json(\"./data/synthetic_data_CTGANSynthesizer.json\")\n",
    "df_test = pd.read_json(\"./data/testset.json\")\n",
    "\n",
    "df_train.drop(columns=['fnlwgt'], inplace=True)\n",
    "df_test.drop(columns=['fnlwgt'], inplace=True)\n",
    "\n",
    "ratio_features = [\"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "ordinal_features = [\"education-num\"]\n",
    "nominal_features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'age', 'hours-per-week', 'capital-gain', 'capital-loss']\n",
    "target = 'income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = X.reset_index(drop=True)\n",
    "    cols = list(X.columns)\n",
    "    X[cols] = X[cols].replace([\" ?\"], np.nan)\n",
    "    X = X.dropna()\n",
    "    def strip_str(x):\n",
    "        if isinstance(x, str):\n",
    "            return x.strip()\n",
    "        else:\n",
    "            return x\n",
    "    X = X.applymap(strip_str)\n",
    "    # X[\"relationship\"] = X[\"relationship\"].replace([\"Husband\", \"Wife\"], \"Married\")\n",
    "    X[\"hours-per-week\"] = pd.cut(\n",
    "        x=X[\"hours-per-week\"],\n",
    "        bins=[0.9, 25, 39, 40, 55, 100],\n",
    "        labels=[\"PartTime\", \"MidTime\", \"FullTime\", \"OverTime\", \"BrainDrain\"],\n",
    "    )\n",
    "    X.age = pd.qcut(X.age, q=5)\n",
    "    X[\"capital-gain\"] = pd.cut(\n",
    "        x=X[\"capital-gain\"],\n",
    "        bins=[-1, 0, 5000, 10000, 50000, 100000],\n",
    "        labels=[\"NoGain\", \"LowGain\", \"MediumGain\", \"HighGain\", \"VeryHighGain\"],\n",
    "    )\n",
    "    X[\"capital-loss\"] = pd.cut(\n",
    "        x=X[\"capital-loss\"],\n",
    "        bins=[-1, 0, 1000, 2000, 5000, 100000],\n",
    "        labels=[\"NoLoss\", \"LowLoss\", \"MediumLoss\", \"HighLoss\", \"VeryHighLoss\"],\n",
    "    )\n",
    "\n",
    "    return X\n",
    "\n",
    "df_train = clean_data(df_train.dropna())\n",
    "df_test = clean_data(df_test.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == \"category\":\n",
    "        df_train[col] = df_train[col].astype(\"object\")\n",
    "        df_test[col] = df_test[col].astype(\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import create_model, train_and_evaluate, describe_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8366259015365318\n",
      "Precision      0.815639353554005\n",
      "Recall         0.7010494485756561\n",
      "F1             0.7318629810496294\n"
     ]
    }
   ],
   "source": [
    "## Train baseline\n",
    "model = create_model(clf, nominal_features)\n",
    "y_test, y_pred = train_and_evaluate(model, df_train, df_test, target, drop_na=True)\n",
    "metrics = describe_model(y_test, y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split_data\n",
    "from utils_fairness import search_bias, calc_fairness_score, explain_detected_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_data(df_train, target, drop_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "model.fit(X_train, y_train)\n",
    "probs = pd.Series(model.predict_proba(X_train)[:, 1]) # we select for target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_subset, _ = search_bias(X_train, y_train, probs, 1, penalty=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'education-num': [11, 13, 14], 'capital-loss': ['NoLoss'], 'sex': ['Male'], 'race': ['Black'], 'occupation': ['Prof-specialty', 'Protective-serv']}, 7.357)\n"
     ]
    }
   ],
   "source": [
    "print(privileged_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive Attributes: ['capital-loss', 'education-num', 'occupation', 'race', 'sex']\n",
      "\n",
      "                               Group Distance  Proportion  Counts   P-Value\n",
      "        Exec-managerial, White, Male    0.486    0.042460    1585  0.00e+00\n",
      "         Prof-specialty, White, Male    0.373    0.061052    2279  0.00e+00\n",
      "                     Exec-managerial    0.409    0.067240    2510  0.00e+00\n",
      "                Prof-specialty, Male    0.348    0.078464    2929  0.00e+00\n",
      "               Exec-managerial, Male    0.482    0.051140    1909  0.00e+00\n",
      "       NoLoss, Exec-managerial, Male    0.472    0.039326    1468  0.00e+00\n",
      "              Exec-managerial, White    0.417    0.054971    2052  0.00e+00\n",
      "                              Female   -0.118    0.371481   13867 2.38e-317\n",
      "             NoLoss, Exec-managerial    0.396    0.051381    1918 2.51e-312\n",
      "NoLoss, Exec-managerial, White, Male    0.479    0.032495    1213 3.98e-283\n",
      "\n",
      "Weighted Mean Statistical Distance: 0.13175298419252776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fairlens.scorer.FairnessScorer at 0x11fa980a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_fairness_score(df_train, privileged_subset[0].keys(), target, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our detected privileged group has a size of 110, we observe 0.0455 as the average probability of earning >50k, but our model predicts 0.2014\n"
     ]
    }
   ],
   "source": [
    "explain_detected_bias(df_train, probs, target, privileged_subset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_fairness import transform_to_bias_dataset, describe_fairness, scan_and_calculate_fairness, plot_fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bias = transform_to_bias_dataset(df_train, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)\n",
    "df_test_bias = transform_to_bias_dataset(df_test, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.027316204577818276\n",
      "average_odds_difference         -0.22859767869483066\n",
      "equal_opportunity_difference    -0.41778127458693937\n",
      "disparate_impact                1.2003188335706674\n",
      "theil_index                     0.10603210355698797\n"
     ]
    }
   ],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "y_test, y_pred = train_and_evaluate(model, df_train, df_train, target, drop_na=True)\n",
    "metrics = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics, priviliged_subsets = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"statistical_parity_difference\",\n",
    "        \"average_abs_odds_difference\",\n",
    "        \"equal_opportunity_difference\",\n",
    "        \"disparate_impact\",\n",
    "        \"theil_index\",\n",
    "    ]\n",
    "), {}\n",
    "\n",
    "for i in [1e-17, 1e-10, 0.001, 0.01, 0.1, 0, 1, 5, 10, 25, 50, 100]:\n",
    "    metrics, priv = scan_and_calculate_fairness(model, df_train, target, i)    \n",
    "    df_fairness_metrics.loc[f\"{i}\"] = metrics.values()\n",
    "    priviliged_subsets[f\"{i}\"] = priv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics.to_json(\"./results/fairness_metrics_synthetic.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn import clone\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from utils_fairness import create_aif360_standardDataset, compute_metrics, reweight_mitigation\n",
    "from utils import plot_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_one_hot_encoding(X_train, X_test, nominal_features):\n",
    "    X_train = pd.get_dummies(X_train, columns=nominal_features)\n",
    "    X_test = pd.get_dummies(X_test, columns=nominal_features)\n",
    "\n",
    "    X_train, X_test = X_train.align(X_test, join='outer', axis=1, fill_value=0)\n",
    "\n",
    "    X_train.index = X_train.index\n",
    "    X_test.index = X_test.index\n",
    "    # X_train[X_train.columns] = X_train[X_train.columns].astype(int)\n",
    "    # Xtest[X_test.columns] = X_test[X_test.columns].astype(int)\n",
    "    return X_train, X_test\n",
    "\n",
    "_df_train, _df_test = custom_one_hot_encoding(df_train, df_test, [feature for feature in nominal_features if feature not in list(privileged_subset[0].keys())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create (un)privileged groups\n",
    "privileged_groups = [{key: 1 for key in list(privileged_subset[0].keys())}]\n",
    "unprivileged_groups = [{key: 0 for key in list(privileged_subset[0].keys())}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset\n",
    "train_dataset = create_aif360_standardDataset(_df_train.dropna(), [], target, 1, list(privileged_subset[0].keys()), list(privileged_subset[0].values()))\n",
    "test_dataset = create_aif360_standardDataset(_df_test.dropna(), [], target, 1, list(privileged_subset[0].keys()), list(privileged_subset[0].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "RW.fit(train_dataset)\n",
    "\n",
    "train_dataset_reweight = RW.transform(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8015051740357478\n",
      "Precision      0.7979767681615386\n",
      "Recall         0.6082894522935671\n",
      "F1             0.6231133374470346\n"
     ]
    }
   ],
   "source": [
    "model = clone(clf)\n",
    "model.fit(train_dataset.features, train_dataset.labels.ravel())\n",
    "y_pred = model.predict(test_dataset.features)\n",
    "\n",
    "_ = describe_model(test_dataset.labels.ravel(), y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.27325293449977367\n",
      "average_odds_difference         0.3160490306583643\n",
      "equal_opportunity_difference    0.5220668823049727\n",
      "disparate_impact                20.055737563922488\n",
      "theil_index                     0.10899556247160261\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(train_dataset.features)\n",
    "_ = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mitigated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8026549597574998\n",
      "Precision      0.8029206959222099\n",
      "Recall         0.6096403351718331\n",
      "F1             0.6249891623141524\n"
     ]
    }
   ],
   "source": [
    "# mitigated model\n",
    "model = clone(clf)\n",
    "model.fit(train_dataset_reweight.features, train_dataset_reweight.labels.ravel(), sample_weight=train_dataset_reweight.instance_weights)\n",
    "y_pred = model.predict(test_dataset.features)\n",
    "\n",
    "_ = describe_model(test_dataset.labels.ravel(), y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   -0.00918177177345883\n",
      "average_odds_difference         -0.16461033371776407\n",
      "equal_opportunity_difference    -0.250432730133753\n",
      "disparate_impact                0.9468423739431331\n",
      "theil_index                     0.11570285629695416\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(train_dataset.features)\n",
    "_ = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias detection & mitigation until bias free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"statistical_parity_difference\",\n",
    "        \"average_abs_odds_difference\",\n",
    "        \"equal_opportunity_difference\",\n",
    "        \"disparate_impact\",\n",
    "        \"theil_index\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(\n",
    "    columns=['acc', 'prec', 'rec', 'f1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = None\n",
    "\n",
    "weights_hist = [weights]\n",
    "max_iter = 10\n",
    "for i in tqdm(range(max_iter)):\n",
    "    X_train, y_train = split_data(df_train, target, True)\n",
    "    X_test, y_test = split_data(df_test, target, True)\n",
    "    weights, model_metrics, fair_metrics = reweight_mitigation(clf, nominal_features, target, X_train, y_train, X_test, y_test, penalty=1, sample_weights=weights)\n",
    "    if model_metrics is None and fair_metrics is None and weights is None:\n",
    "        break\n",
    "\n",
    "    df_metrics.loc[f\"mitigation_{i}\"] = model_metrics.values()\n",
    "    df_fairness_metrics.loc[f\"mitigation_{i}\"] = fair_metrics.values()\n",
    "    weights_hist.append(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prepare_data_fair_learning, plot_fairlearning_results\n",
    "from utils_fairness import get_fair_learning_scoring\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from aif360.sklearn.preprocessing import LearnedFairRepresentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bias = transform_to_bias_dataset(df_train, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)\n",
    "df_test_bias = transform_to_bias_dataset(df_train, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)\n",
    "\n",
    "X_train, y_train, X_test, y_test = prepare_data_fair_learning(df_train_bias, df_test_bias, nominal_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_delta = get_fair_learning_scoring(list(privileged_subset[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfr = LearnedFairRepresentations(\n",
    "    list(privileged_subset[0].keys()),\n",
    "    n_prototypes=25,\n",
    "    max_iter=100,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"reconstruct_weight\": [1e-2, 1e-3, 1e-4],\n",
    "    \"target_weight\": [100, 1000],\n",
    "    \"fairness_weight\": [0, 100, 1000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(lfr, params, scoring=max_delta, cv=3, n_jobs=-1).fit(\n",
    "    X_train, y_train, priv_group=(1,) * len(list(privileged_subset[0].keys()))\n",
    ")\n",
    "res = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8705296150446034\n",
      "Precision      0.813527939120468\n",
      "Recall         0.7641013252007482\n",
      "F1             0.7845435554975462\n"
     ]
    }
   ],
   "source": [
    "model = clone(clf)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "_ = describe_model(y_test, y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.02755801655557158\n",
      "average_odds_difference         -0.22786158429608466\n",
      "equal_opportunity_difference    -0.41620771046420146\n",
      "disparate_impact                1.2020921214075249\n",
      "theil_index                     0.1056484782584031\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "_ = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Grid itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.860671327921991\n",
      "Precision      0.8138180324606257\n",
      "Recall         0.7181291095838941\n",
      "F1             0.7498191506199834\n"
     ]
    }
   ],
   "source": [
    "_ = describe_model(y_test, grid.predict(X_test), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.03001424003868991\n",
      "average_odds_difference         -0.07932585150440108\n",
      "equal_opportunity_difference    -0.123078940466824\n",
      "disparate_impact                1.300142400386899\n",
      "theil_index                     0.12597404950862984\n"
     ]
    }
   ],
   "source": [
    "_ = describe_fairness(y_train, grid.predict(X_train), list(privileged_subset[0].keys()) ,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.2044255136756945\n",
      "Precision      0.10221275683784725\n",
      "Recall                     0.5\n",
      "F1             0.16972864768683274\n"
     ]
    }
   ],
   "source": [
    "model = clone(clf)\n",
    "model.fit(grid.transform(X_train), y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "_ = describe_model(y_test, y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference               0.0\n",
      "average_odds_difference                     0.0\n",
      "equal_opportunity_difference                0.0\n",
      "disparate_impact                            1.0\n",
      "theil_index                     0.028907602900327994\n"
     ]
    }
   ],
   "source": [
    "_ = describe_fairness(y_train, model.predict(X_train), list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Also Transforming test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8625197567574808\n",
      "Precision      0.805220529474548\n",
      "Recall         0.7390573449217117\n",
      "F1             0.7641904608117651\n"
     ]
    }
   ],
   "source": [
    "_ = describe_model(y_test, model.predict(grid.transform(X_test)), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.013506053848352156\n",
      "average_odds_difference         -0.06612768025789179\n",
      "equal_opportunity_difference    -0.06984002098085496\n",
      "disparate_impact                1.0990443948879158\n",
      "theil_index                     0.11691149079993556\n"
     ]
    }
   ],
   "source": [
    "_ = describe_fairness(y_train, model.predict(grid.transform(X_train)), list(privileged_subset[0].keys()) ,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Runs cannot be done, because of the dataset already needs to be one hot encoded for the mitigation, making the `search_bias` function unnecessary and returning not viable resolutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils_fairness import create_aif360_standardDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create (un)privileged groups\n",
    "privileged_groups = [{key: 1 for key in list(privileged_subset[0].keys())}]\n",
    "unprivileged_groups = [{key: 0 for key in list(privileged_subset[0].keys())}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fairness_weight': 1000, 'reconstruct_weight': 0.001, 'target_weight': 100}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 78.20657769578119, L_x: 0.5457422165300079,  L_y: 0.6856380468772482,  L_z: 0.009642227265839843\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          240     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.82066D+01    |proj g|=  1.26856D+01\n",
      "step: 250, loss: 69.53134829158694, L_x: 0.5456077422192046,  L_y: 0.6321676361535841,  L_z: 0.00631403906848631\n",
      "\n",
      "At iterate    1    f=  6.95313D+01    |proj g|=  1.55235D+01\n",
      "step: 500, loss: 62.72247517405184, L_x: 0.5436820946880235,  L_y: 0.548459567054186,  L_z: 0.007875974786538554\n",
      "step: 750, loss: 57.278535815649136, L_x: 0.5447698629527601,  L_y: 0.5203337871745667,  L_z: 0.005244612328329512\n",
      "\n",
      "At iterate    2    f=  5.72785D+01    |proj g|=  1.85726D+01\n",
      "step: 1000, loss: 54.378108638912316, L_x: 0.5481890599350094,  L_y: 0.5199503747202057,  L_z: 0.0023825229778318135\n",
      "\n",
      "At iterate    3    f=  5.43781D+01    |proj g|=  9.67687D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  240      3      5      9     0     0   9.677D+00   5.438D+01\n",
      "  F =   54.378111783971768     \n",
      "\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT        \n"
     ]
    }
   ],
   "source": [
    "TR = LFR(unprivileged_groups=unprivileged_groups,\n",
    "         privileged_groups=privileged_groups,\n",
    "         k=5, Ax=0.001, Ay=100, Az=1000,\n",
    "         verbose=1,\n",
    "         seed=random_state\n",
    ")\n",
    "\n",
    "TR = TR.fit(train_dataset, maxiter=5000, maxfun=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training data and align features\n",
    "train_dataset_lfr = TR.transform(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 37329}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = {}\n",
    "for i in train_dataset_lfr.labels.ravel():\n",
    "    cnt[i] = cnt.get(i, 0) + 1\n",
    "\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8015051740357478\n",
      "Precision      0.7979767681615386\n",
      "Recall         0.6082894522935671\n",
      "F1             0.6231133374470346\n"
     ]
    }
   ],
   "source": [
    "model = clone(clf)\n",
    "model.fit(train_dataset.features, train_dataset.labels.ravel())\n",
    "y_pred = model.predict(test_dataset.features)\n",
    "\n",
    "_ = describe_model(test_dataset.labels.ravel(), y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   -0.034483609300235224\n",
      "average_odds_difference         -0.27993330920799864\n",
      "equal_opportunity_difference    -0.46682402307894044\n",
      "disparate_impact                0.8193715703321012\n",
      "theil_index                     0.11820128511811895\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(train_dataset.features)\n",
    "_ = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.7955744863243055\n",
      "Precision      0.39778724316215275\n",
      "Recall                     0.5\n",
      "F1             0.44307517865934626\n"
     ]
    }
   ],
   "source": [
    "_ = describe_model(df_test_bias[target], [0]*len(df_test_bias[target]), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference               0.0\n",
      "average_odds_difference                     0.0\n",
      "equal_opportunity_difference                0.0\n",
      "disparate_impact                            0.0\n",
      "theil_index                     0.22869080098773423\n"
     ]
    }
   ],
   "source": [
    "_ = describe_fairness(df_train_bias[target], np.array([0]*len(df_train_bias)), list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disparate Impact Remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or have an __index__ method"
     ]
    }
   ],
   "source": [
    "train_dataset.feature_names.index('sex', 'race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = train_dataset.feature_names.index(list(privileged_subset[0].keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:49<00:00,  4.96s/it]\n"
     ]
    }
   ],
   "source": [
    "fairness_metrics = []\n",
    "utility_metrics = []\n",
    "for level in tqdm(np.linspace(0, 1, 10)):\n",
    "    di = DisparateImpactRemover(repair_level=level)\n",
    "    train_repd = di.fit_transform(train_dataset)\n",
    "    test_repd = di.fit_transform(test_dataset)\n",
    "    \n",
    "    #X_tr = train_repd.features # \n",
    "    X_tr = np.delete(train_repd.features, index, axis=1)\n",
    "    #X_te = test_repd.features # \n",
    "    X_te = np.delete(test_repd.features, index, axis=1)\n",
    "    y_tr = train_repd.labels.ravel()\n",
    "    \n",
    "    model = clone(clf)\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    utility_metrics.append(describe_model(test_repd.labels.ravel(), model.predict(X_te), verbose=False))\n",
    "    fairness_metrics.append(describe_fairness(df_train_bias[target], model.predict(X_tr), list(privileged_subset[0].keys()), verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'statistical_parity_difference': 0.02034005114689713,\n",
       "  'average_odds_difference': -0.07412497327729684,\n",
       "  'equal_opportunity_difference': -0.10039339103068445,\n",
       "  'disparate_impact': 1.1598146875827633,\n",
       "  'theil_index': 0.12529740460945935},\n",
       " {'statistical_parity_difference': 0.02034005114689713,\n",
       "  'average_odds_difference': -0.07412497327729684,\n",
       "  'equal_opportunity_difference': -0.10039339103068445,\n",
       "  'disparate_impact': 1.1598146875827633,\n",
       "  'theil_index': 0.12529740460945935},\n",
       " {'statistical_parity_difference': 0.02034005114689713,\n",
       "  'average_odds_difference': -0.07412497327729684,\n",
       "  'equal_opportunity_difference': -0.10039339103068445,\n",
       "  'disparate_impact': 1.1598146875827633,\n",
       "  'theil_index': 0.12529740460945935},\n",
       " {'statistical_parity_difference': 0.02034005114689713,\n",
       "  'average_odds_difference': -0.07412497327729684,\n",
       "  'equal_opportunity_difference': -0.10039339103068445,\n",
       "  'disparate_impact': 1.1598146875827633,\n",
       "  'theil_index': 0.12529740460945935},\n",
       " {'statistical_parity_difference': 0.02034005114689713,\n",
       "  'average_odds_difference': -0.07412497327729684,\n",
       "  'equal_opportunity_difference': -0.10039339103068445,\n",
       "  'disparate_impact': 1.1598146875827633,\n",
       "  'theil_index': 0.12529740460945935},\n",
       " {'statistical_parity_difference': 0.02034005114689713,\n",
       "  'average_odds_difference': -0.07412497327729684,\n",
       "  'equal_opportunity_difference': -0.10039339103068445,\n",
       "  'disparate_impact': 1.1598146875827633,\n",
       "  'theil_index': 0.12529740460945935},\n",
       " {'statistical_parity_difference': 0.02034005114689713,\n",
       "  'average_odds_difference': -0.07412497327729684,\n",
       "  'equal_opportunity_difference': -0.10039339103068445,\n",
       "  'disparate_impact': 1.1598146875827633,\n",
       "  'theil_index': 0.12529740460945935},\n",
       " {'statistical_parity_difference': 0.02034005114689713,\n",
       "  'average_odds_difference': -0.07412497327729684,\n",
       "  'equal_opportunity_difference': -0.10039339103068445,\n",
       "  'disparate_impact': 1.1598146875827633,\n",
       "  'theil_index': 0.12529740460945935},\n",
       " {'statistical_parity_difference': 0.02034005114689713,\n",
       "  'average_odds_difference': -0.07412497327729684,\n",
       "  'equal_opportunity_difference': -0.10039339103068445,\n",
       "  'disparate_impact': 1.1598146875827633,\n",
       "  'theil_index': 0.12529740460945935},\n",
       " {'statistical_parity_difference': 0.02034005114689713,\n",
       "  'average_odds_difference': -0.07412497327729684,\n",
       "  'equal_opportunity_difference': -0.10039339103068445,\n",
       "  'disparate_impact': 1.1598146875827633,\n",
       "  'theil_index': 0.12529740460945935}]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
