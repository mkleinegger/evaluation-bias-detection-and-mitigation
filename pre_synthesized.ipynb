{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random_state = 12041500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df_train = pd.read_json(\"./data/trainset.json\")\n",
    "    df_test = pd.read_json(\"./data/testset.json\")\n",
    "\n",
    "    df_train.drop(columns=['fnlwgt'], inplace=True)\n",
    "    df_test.drop(columns=['fnlwgt'], inplace=True)\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "df_train, df_test = load_data()\n",
    "\n",
    "ratio_features = [\"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "ordinal_features = [\"education-num\"]\n",
    "nominal_features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex']\n",
    "target = 'income'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import create_model, train_and_evaluate, describe_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8477056548552315\n",
      "Precision      0.8009474218724006\n",
      "Recall         0.7607582564719824\n",
      "F1             0.777270198343837\n"
     ]
    }
   ],
   "source": [
    "## Train baseline\n",
    "model = create_model(clf, nominal_features)\n",
    "y_test, y_pred = train_and_evaluate(model, df_train, df_test, target, drop_na=True)\n",
    "metrics = describe_model(y_test, y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split_data\n",
    "from utils_fairness import search_bias, calc_fairness_score, explain_detected_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_data(df_train, target, drop_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "model.fit(X_train, y_train)\n",
    "probs = pd.Series(model.predict_proba(X_train)[:, 1]) # we select for target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_subset, _ = search_bias(X_train, y_train, probs, 1, penalty=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'capital-gain': [1409, 1424, 1455, 1506, 1797, 2105, 2174, 2202, 2228, 2290, 2329, 2346, 2354, 2407, 2414, 2463, 2580, 2597, 2635, 2653, 2829, 2885, 2907, 2936, 2961, 3137, 3273, 3325, 3411, 3432, 3456, 3464, 3471, 3674, 3781, 3818, 3908, 3942, 4064, 4101, 4416, 4508, 4650, 4865, 4931, 5013, 5455, 5721, 6360, 6497, 6723, 6767, 6849, 7443, 7978, 10566, 22040, 34095, 41310]}, 547.3998)\n"
     ]
    }
   ],
   "source": [
    "print(privileged_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive Attributes: ['capital-gain']\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Group, Distance, Proportion, Counts, P-Value]\n",
      "Index: []\n",
      "\n",
      "Weighted Mean Statistical Distance: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fairlens.scorer.FairnessScorer at 0x2c47e50f0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_fairness_score(df_train, privileged_subset[0].keys(), target, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our detected privileged group has a size of 984, we observe 0.0 as the average probability of earning >50k, but our model predicts 0.2604\n"
     ]
    }
   ],
   "source": [
    "explain_detected_bias(df_train, probs, target, privileged_subset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_fairness import transform_to_bias_dataset, describe_fairness, scan_and_calculate_fairness, plot_fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764 Na rows removed!\n",
      "202 Na rows removed!\n"
     ]
    }
   ],
   "source": [
    "df_train_bias = transform_to_bias_dataset(df_train, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)\n",
    "df_test_bias = transform_to_bias_dataset(df_test, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   -0.12179388555614121\n",
      "average_odds_difference         0.1719641410226968\n",
      "equal_opportunity_difference    0.6004080756013745\n",
      "disparate_impact                0.6155134201070837\n",
      "theil_index                     0.12170921644827831\n"
     ]
    }
   ],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "y_test, y_pred = train_and_evaluate(model, df_train, df_train, target, drop_na=True)\n",
    "metrics = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics, priviliged_subsets = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"statistical_parity_difference\",\n",
    "        \"average_abs_odds_difference\",\n",
    "        \"equal_opportunity_difference\",\n",
    "        \"disparate_impact\",\n",
    "        \"theil_index\",\n",
    "    ]\n",
    "), {}\n",
    "\n",
    "for i in [1e-17, 1e-10, 0.001, 0.01, 0.1, 0, 1, 5, 10, 25, 50, 100]:\n",
    "    metrics, priv = scan_and_calculate_fairness(model, df_train, target, i)    \n",
    "    df_fairness_metrics.loc[f\"{i}\"] = metrics.values()\n",
    "    priviliged_subsets[f\"{i}\"] = priv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>average_abs_odds_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>theil_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1e-17</th>\n",
       "      <td>-0.066640</td>\n",
       "      <td>0.199234</td>\n",
       "      <td>0.600408</td>\n",
       "      <td>0.746289</td>\n",
       "      <td>0.121709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-10</th>\n",
       "      <td>-0.066640</td>\n",
       "      <td>0.199234</td>\n",
       "      <td>0.600408</td>\n",
       "      <td>0.746289</td>\n",
       "      <td>0.121709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>-0.066640</td>\n",
       "      <td>0.199234</td>\n",
       "      <td>0.600408</td>\n",
       "      <td>0.746289</td>\n",
       "      <td>0.121709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>-0.066640</td>\n",
       "      <td>0.199234</td>\n",
       "      <td>0.600408</td>\n",
       "      <td>0.746289</td>\n",
       "      <td>0.121709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>-0.069909</td>\n",
       "      <td>0.197622</td>\n",
       "      <td>0.600408</td>\n",
       "      <td>0.737043</td>\n",
       "      <td>0.121709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.066640</td>\n",
       "      <td>0.199234</td>\n",
       "      <td>0.600408</td>\n",
       "      <td>0.746289</td>\n",
       "      <td>0.121709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.121794</td>\n",
       "      <td>0.171964</td>\n",
       "      <td>0.600408</td>\n",
       "      <td>0.615513</td>\n",
       "      <td>0.121709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.214702</td>\n",
       "      <td>0.126118</td>\n",
       "      <td>0.600408</td>\n",
       "      <td>0.475085</td>\n",
       "      <td>0.121709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.280192</td>\n",
       "      <td>0.093735</td>\n",
       "      <td>0.600408</td>\n",
       "      <td>0.409512</td>\n",
       "      <td>0.121709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.537335</td>\n",
       "      <td>-0.034031</td>\n",
       "      <td>0.600408</td>\n",
       "      <td>0.266332</td>\n",
       "      <td>0.121709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.636882</td>\n",
       "      <td>-0.083315</td>\n",
       "      <td>0.600408</td>\n",
       "      <td>0.235742</td>\n",
       "      <td>0.121709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.636882</td>\n",
       "      <td>-0.083315</td>\n",
       "      <td>0.600408</td>\n",
       "      <td>0.235742</td>\n",
       "      <td>0.121709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statistical_parity_difference  average_abs_odds_difference  \\\n",
       "1e-17                      -0.066640                     0.199234   \n",
       "1e-10                      -0.066640                     0.199234   \n",
       "0.001                      -0.066640                     0.199234   \n",
       "0.01                       -0.066640                     0.199234   \n",
       "0.1                        -0.069909                     0.197622   \n",
       "0                          -0.066640                     0.199234   \n",
       "1                          -0.121794                     0.171964   \n",
       "5                          -0.214702                     0.126118   \n",
       "10                         -0.280192                     0.093735   \n",
       "25                         -0.537335                    -0.034031   \n",
       "50                         -0.636882                    -0.083315   \n",
       "100                        -0.636882                    -0.083315   \n",
       "\n",
       "       equal_opportunity_difference  disparate_impact  theil_index  \n",
       "1e-17                      0.600408          0.746289     0.121709  \n",
       "1e-10                      0.600408          0.746289     0.121709  \n",
       "0.001                      0.600408          0.746289     0.121709  \n",
       "0.01                       0.600408          0.746289     0.121709  \n",
       "0.1                        0.600408          0.737043     0.121709  \n",
       "0                          0.600408          0.746289     0.121709  \n",
       "1                          0.600408          0.615513     0.121709  \n",
       "5                          0.600408          0.475085     0.121709  \n",
       "10                         0.600408          0.409512     0.121709  \n",
       "25                         0.600408          0.266332     0.121709  \n",
       "50                         0.600408          0.235742     0.121709  \n",
       "100                        0.600408          0.235742     0.121709  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_diff(data, expectations, target, subset):\n",
    "    if len(subset) == 0:\n",
    "        return {\n",
    "            \"count\": 0,\n",
    "            \"expected_probability\": np.NaN,\n",
    "            \"model_probability\": np.NaN\n",
    "        }\n",
    "\n",
    "    _df = data.copy()\n",
    "    _df[\"expectations\"] = expectations.copy()\n",
    "\n",
    "    _to_choose = _df[subset.keys()].isin(subset).all(axis=1)\n",
    "    _to_choose = _df.loc[_to_choose]\n",
    "\n",
    "    return {\n",
    "        \"count\": len(_to_choose),\n",
    "        \"expected_probability\": np.round(_to_choose[target].mean(), 4),\n",
    "        \"model_probability\": np.round(_to_choose[\"expectations\"].mean(), 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "model.fit(X_train, y_train)\n",
    "probs = pd.Series(model.predict_proba(X_train)[:, 1]) # we select for target label\n",
    "\n",
    "df_probs_diff = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"count\",\n",
    "        \"expected_probability\",\n",
    "        \"model_probability\",\n",
    "    ]\n",
    ")\n",
    "for penalty, priv in priviliged_subsets.items():\n",
    "    df_probs_diff.loc[penalty] = calc_diff(df_train, probs, target, priv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>expected_probability</th>\n",
       "      <th>model_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1e-17</th>\n",
       "      <td>1165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-10</th>\n",
       "      <td>1191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>1191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>1191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>1177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  expected_probability  model_probability\n",
       "1e-17   1165                   0.0             0.2594\n",
       "1e-10   1191                   0.0             0.2590\n",
       "0.001   1191                   0.0             0.2590\n",
       "0.01    1191                   0.0             0.2590\n",
       "0.1     1177                   0.0             0.2582\n",
       "0       1165                   0.0             0.2594\n",
       "1        984                   0.0             0.2604\n",
       "5        671                   0.0             0.2698\n",
       "10       513                   0.0             0.2686\n",
       "25       213                   0.0             0.2538\n",
       "50        96                   0.0             0.2798\n",
       "100       96                   0.0             0.2798"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probs_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics.to_json(\"./results/fairness_metrics_original.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = load_data()\n",
    "nominal_features = nominal_features + ['age', 'hours-per-week', 'capital-gain', 'capital-loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def clean_data(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = X.reset_index(drop=True)\n",
    "    cols = list(X.columns)\n",
    "    X[cols] = X[cols].replace([\" ?\"], np.nan)\n",
    "    X = X.dropna()\n",
    "    def strip_str(x):\n",
    "        if isinstance(x, str):\n",
    "            return x.strip()\n",
    "        else:\n",
    "            return x\n",
    "    X = X.applymap(strip_str)\n",
    "    # X[\"relationship\"] = X[\"relationship\"].replace([\"Husband\", \"Wife\"], \"Married\")\n",
    "    X[\"hours-per-week\"] = pd.cut(\n",
    "        x=X[\"hours-per-week\"],\n",
    "        bins=[0.9, 25, 39, 40, 55, 100],\n",
    "        labels=[\"PartTime\", \"MidTime\", \"FullTime\", \"OverTime\", \"BrainDrain\"],\n",
    "    )\n",
    "    X.age = pd.qcut(X.age, q=5)\n",
    "    X[\"capital-gain\"] = pd.cut(\n",
    "        x=X[\"capital-gain\"],\n",
    "        bins=[-1, 0, 5000, 10000, 50000, X[\"capital-gain\"].max() + 1],\n",
    "        labels=[\"NoGain\", \"LowGain\", \"MediumGain\", \"HighGain\", \"VeryHighGain\"],\n",
    "    )\n",
    "    X[\"capital-loss\"] = pd.cut(\n",
    "        x=X[\"capital-loss\"],\n",
    "        bins=[-1, 0, 1000, 2000, 5000, 100000],\n",
    "        labels=[\"NoLoss\", \"LowLoss\", \"MediumLoss\", \"HighLoss\", \"VeryHighLoss\"],\n",
    "    )\n",
    "\n",
    "    return X\n",
    "\n",
    "df_train = clean_data(df_train.dropna())\n",
    "df_test = clean_data(df_test.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == \"category\":\n",
    "        df_train[col] = df_train[col].astype(\"object\")\n",
    "        df_test[col] = df_test[col].astype(\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import create_model, train_and_evaluate, describe_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8526183756663531\n",
      "Precision      0.8096755453959336\n",
      "Recall         0.7656258130687443\n",
      "F1             0.7835223861090438\n"
     ]
    }
   ],
   "source": [
    "## Train baseline\n",
    "model = create_model(clf, nominal_features)\n",
    "y_test, y_pred = train_and_evaluate(model, df_train, df_test, target, drop_na=True)\n",
    "metrics = describe_model(y_test, y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split_data\n",
    "from utils_fairness import search_bias, calc_fairness_score, explain_detected_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_data(df_train, target, drop_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "model.fit(X_train, y_train)\n",
    "probs = pd.Series(model.predict_proba(X_train)[:, 1]) # we select for target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_subset, _ = search_bias(X_train, y_train, probs, 1, penalty=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'hours-per-week': ['FullTime', 'MidTime', 'OverTime'], 'workclass': ['Federal-gov', 'Local-gov', 'Private'], 'relationship': ['Husband', 'Wife'], 'capital-loss': ['HighLoss']}, 19.2157)\n"
     ]
    }
   ],
   "source": [
    "print(privileged_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive Attributes: ['capital-loss', 'hours-per-week', 'relationship', 'workclass']\n",
      "\n",
      "                     Group Distance  Proportion  Counts   P-Value\n",
      "        Own-child, Private    0.230    0.117701    4509  0.00e+00\n",
      "                 Own-child    0.229    0.150852    5779  0.00e+00\n",
      " NoLoss, OverTime, Husband   -0.305    0.109948    4212  0.00e+00\n",
      "         OverTime, Husband   -0.324    0.119189    4566  0.00e+00\n",
      "          Husband, Private   -0.195    0.267352   10242 4.94e-324\n",
      "           NoLoss, Husband   -0.190    0.381895   14630 4.94e-324\n",
      "NoLoss, Own-child, Private    0.230    0.114986    4405 4.94e-324\n",
      "                   Husband   -0.208    0.407685   15618 4.94e-324\n",
      "         NoLoss, Own-child    0.230    0.147224    5640 4.94e-324\n",
      "  NoLoss, Husband, Private   -0.177    0.250568    9599 1.20e-315\n",
      "\n",
      "Weighted Mean Statistical Distance: 0.14188452864128123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fairlens.scorer.FairnessScorer at 0x2c47dc130>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_fairness_score(df_train, privileged_subset[0].keys(), target, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our detected privileged group has a size of 90, we observe 0.2222 as the average probability of earning >50k, but our model predicts 0.5559\n"
     ]
    }
   ],
   "source": [
    "explain_detected_bias(df_train, probs, target, privileged_subset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_fairness import transform_to_bias_dataset, describe_fairness, scan_and_calculate_fairness, plot_fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bias = transform_to_bias_dataset(df_train, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)\n",
    "df_test_bias = transform_to_bias_dataset(df_test, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   -0.34679406112724614\n",
      "average_odds_difference         -0.35125457169171503\n",
      "equal_opportunity_difference    -0.33872148084373654\n",
      "disparate_impact                0.3630313162968948\n",
      "theil_index                     0.1177542234136661\n"
     ]
    }
   ],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "y_test, y_pred = train_and_evaluate(model, df_train, df_train, target, drop_na=True)\n",
    "metrics = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics, priviliged_subsets = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"statistical_parity_difference\",\n",
    "        \"average_abs_odds_difference\",\n",
    "        \"equal_opportunity_difference\",\n",
    "        \"disparate_impact\",\n",
    "        \"theil_index\",\n",
    "    ]\n",
    "), {}\n",
    "\n",
    "for i in [1e-17, 1e-10, 0.001, 0.01, 0.1, 0, 1, 5, 10, 25, 50, 100]:\n",
    "    metrics, priv = scan_and_calculate_fairness(model, df_train, target, i)    \n",
    "    df_fairness_metrics.loc[f\"{i}\"] = metrics.values()\n",
    "    priviliged_subsets[f\"{i}\"] = priv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>average_abs_odds_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>theil_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1e-17</th>\n",
       "      <td>0.266412</td>\n",
       "      <td>0.358207</td>\n",
       "      <td>0.618180</td>\n",
       "      <td>655.640546</td>\n",
       "      <td>0.117754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-10</th>\n",
       "      <td>0.266384</td>\n",
       "      <td>0.358199</td>\n",
       "      <td>0.618180</td>\n",
       "      <td>655.371397</td>\n",
       "      <td>0.117754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>0.266384</td>\n",
       "      <td>0.358199</td>\n",
       "      <td>0.618180</td>\n",
       "      <td>655.371397</td>\n",
       "      <td>0.117754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>-0.285315</td>\n",
       "      <td>-0.384832</td>\n",
       "      <td>-0.388161</td>\n",
       "      <td>0.409693</td>\n",
       "      <td>0.117754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.126427</td>\n",
       "      <td>0.175246</td>\n",
       "      <td>0.343735</td>\n",
       "      <td>2.724830</td>\n",
       "      <td>0.117754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266412</td>\n",
       "      <td>0.358207</td>\n",
       "      <td>0.618180</td>\n",
       "      <td>655.640546</td>\n",
       "      <td>0.117754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.346794</td>\n",
       "      <td>-0.351255</td>\n",
       "      <td>-0.338721</td>\n",
       "      <td>0.363031</td>\n",
       "      <td>0.117754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.424474</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.279585</td>\n",
       "      <td>0.316125</td>\n",
       "      <td>0.117754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statistical_parity_difference  average_abs_odds_difference  \\\n",
       "1e-17                       0.266412                     0.358207   \n",
       "1e-10                       0.266384                     0.358199   \n",
       "0.001                       0.266384                     0.358199   \n",
       "0.01                       -0.285315                    -0.384832   \n",
       "0.1                         0.126427                     0.175246   \n",
       "0                           0.266412                     0.358207   \n",
       "1                          -0.346794                    -0.351255   \n",
       "5                          -0.424474                    -0.311169   \n",
       "10                          0.000000                     0.000000   \n",
       "25                          0.000000                     0.000000   \n",
       "50                          0.000000                     0.000000   \n",
       "100                         0.000000                     0.000000   \n",
       "\n",
       "       equal_opportunity_difference  disparate_impact  theil_index  \n",
       "1e-17                      0.618180        655.640546     0.117754  \n",
       "1e-10                      0.618180        655.371397     0.117754  \n",
       "0.001                      0.618180        655.371397     0.117754  \n",
       "0.01                      -0.388161          0.409693     0.117754  \n",
       "0.1                        0.343735          2.724830     0.117754  \n",
       "0                          0.618180        655.640546     0.117754  \n",
       "1                         -0.338721          0.363031     0.117754  \n",
       "5                         -0.279585          0.316125     0.117754  \n",
       "10                         0.000000          1.000000     0.000000  \n",
       "25                         0.000000          1.000000     0.000000  \n",
       "50                         0.000000          1.000000     0.000000  \n",
       "100                        0.000000          1.000000     0.000000  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics.to_json(\"./results/fairness_metrics_original_cleaned.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "model.fit(X_train, y_train)\n",
    "probs = pd.Series(model.predict_proba(X_train)[:, 1]) # we select for target label\n",
    "\n",
    "df_probs_diff = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"count\",\n",
    "        \"expected_probability\",\n",
    "        \"model_probability\",\n",
    "    ]\n",
    ")\n",
    "for penalty, priv in priviliged_subsets.items():\n",
    "    df_probs_diff.loc[penalty] = calc_diff(df_train, probs, target, priv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>expected_probability</th>\n",
       "      <th>model_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1e-17</th>\n",
       "      <td>9829</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-10</th>\n",
       "      <td>9826</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>9826</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>60</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>382</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9829</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.5559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>203</td>\n",
       "      <td>0.4433</td>\n",
       "      <td>0.6139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  expected_probability  model_probability\n",
       "1e-17   9829                0.0095             0.0210\n",
       "1e-10   9826                0.0095             0.0210\n",
       "0.001   9826                0.0095             0.0210\n",
       "0.01      60                0.0667             0.4962\n",
       "0.1      382                0.0681             0.2038\n",
       "0       9829                0.0095             0.0210\n",
       "1         90                0.2222             0.5559\n",
       "5        203                0.4433             0.6139\n",
       "10         0                   NaN                NaN\n",
       "25         0                   NaN                NaN\n",
       "50         0                   NaN                NaN\n",
       "100        0                   NaN                NaN"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probs_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDFed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = load_data()\n",
    "nominal_features = nominal_features + ['age', 'hours-per-week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def clean_data(X: pd.DataFrame) -> pd.DataFrame:\n",
    "     # Function to transform numerical attributes into their PDF values\n",
    "    def transform_to_pdf(data, numerical_columns, target):\n",
    "        transformed_data = data.copy()\n",
    "        for column in numerical_columns:\n",
    "            if column not in ['sex', target]:\n",
    "                kde = gaussian_kde(data[column].dropna())\n",
    "                transformed_data[column] = kde(data[column])\n",
    "        return transformed_data\n",
    "\n",
    "    # Transforming the numerical attributes\n",
    "    # X = X.drop(columns=[\"fnlwgt\", \"education\"], errors=\"ignore\")\n",
    "    cols = list(X.columns)\n",
    "    X[cols] = X[cols].replace([\" ?\"], np.nan)\n",
    "    X = X.dropna()\n",
    "\n",
    "    def strip_str(x):\n",
    "        if isinstance(x, str):\n",
    "            return x.strip()\n",
    "        else:\n",
    "            return x\n",
    "    X = X.applymap(strip_str)\n",
    "\n",
    "    # X[\"relationship\"] = X[\"relationship\"].replace([\"Husband\", \"Wife\"], \"Married\")\n",
    "    X = transform_to_pdf(X,['age', 'hours-per-week', 'capital-gain', 'capital-loss'], target)\n",
    "\n",
    "    return X\n",
    "\n",
    "df_train = clean_data(df_train.dropna())\n",
    "df_test = clean_data(df_test.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == \"category\":\n",
    "        df_train[col] = df_train[col].astype(\"object\")\n",
    "        df_test[col] = df_test[col].astype(\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import create_model, train_and_evaluate, describe_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8140482910003136\n",
      "Precision      0.7474219922851064\n",
      "Recall         0.7703756597408014\n",
      "F1             0.7571757743396905\n"
     ]
    }
   ],
   "source": [
    "## Train baseline\n",
    "model = create_model(clf, nominal_features)\n",
    "y_test, y_pred = train_and_evaluate(model, df_train, df_test, target, drop_na=True)\n",
    "metrics = describe_model(y_test, y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split_data\n",
    "from utils_fairness import search_bias, calc_fairness_score, explain_detected_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_data(df_train, target, drop_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "model.fit(X_train, y_train)\n",
    "probs = pd.Series(model.predict_proba(X_train)[:, 1]) # we select for target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_subset, _ = search_bias(X_train, y_train, probs, 1, penalty=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'capital-gain': [1.108469510907749e-06, 5.765883500686317e-06, 6.10361661605396e-06, 6.812113570428972e-06, 7.014401995094196e-06, 7.1738364190331214e-06, 7.194661828926502e-06, 7.660438928410234e-06, 7.947687124397542e-06, 8.667196401393174e-06, 8.825617371877361e-06, 8.867547263415679e-06, 8.974838428689815e-06, 9.017723059882917e-06, 9.383215882157025e-06, 9.392498484571787e-06, 9.466276197254861e-06, 9.603682302865236e-06, 1.0040343731611617e-05, 1.0775653765085864e-05, 1.0920757983701274e-05, 1.1258138748347011e-05, 1.170231032823149e-05, 1.3770732245764749e-05, 1.405480988072596e-05, 1.502609359416476e-05, 1.910843724102672e-05, 1.9325712488370405e-05, 2.1109643625328754e-05, 2.3619222072924518e-05, 2.6465815179851564e-05, 2.779276464904525e-05, 2.9315798274844017e-05, 3.351370696288232e-05, 0.00010547658630157628, 0.00012424286014113114]}, 34.1879)\n"
     ]
    }
   ],
   "source": [
    "print(privileged_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive Attributes: ['capital-gain']\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Group, Distance, Proportion, Counts, P-Value]\n",
      "Index: []\n",
      "\n",
      "Weighted Mean Statistical Distance: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fairlens.scorer.FairnessScorer at 0x2c230ec20>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_fairness_score(df_train, privileged_subset[0].keys(), target, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our detected privileged group has a size of 785, we observe 0.0 as the average probability of earning >50k, but our model predicts 0.2671\n"
     ]
    }
   ],
   "source": [
    "explain_detected_bias(df_train, probs, target, privileged_subset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_fairness import transform_to_bias_dataset, describe_fairness, scan_and_calculate_fairness, plot_fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bias = transform_to_bias_dataset(df_train, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)\n",
    "df_test_bias = transform_to_bias_dataset(df_test, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.18843905929928836\n",
      "average_odds_difference         0.3432843498456296\n",
      "equal_opportunity_difference    0.6444372852233677\n",
      "disparate_impact                15.792466154994136\n",
      "theil_index                     0.10592275572368795\n"
     ]
    }
   ],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "y_test, y_pred = train_and_evaluate(model, df_train, df_train, target, drop_na=True)\n",
    "metrics = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics, priviliged_subsets = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"statistical_parity_difference\",\n",
    "        \"average_abs_odds_difference\",\n",
    "        \"equal_opportunity_difference\",\n",
    "        \"disparate_impact\",\n",
    "        \"theil_index\",\n",
    "    ]\n",
    "), {}\n",
    "\n",
    "for i in [1e-17, 1e-10, 0.001, 0.01, 0.1, 0, 1, 5, 10, 25, 50, 100]:\n",
    "    metrics, priv = scan_and_calculate_fairness(model, df_train, target, i)    \n",
    "    df_fairness_metrics.loc[f\"{i}\"] = metrics.values()\n",
    "    priviliged_subsets[f\"{i}\"] = priv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>average_abs_odds_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>theil_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1e-17</th>\n",
       "      <td>0.194652</td>\n",
       "      <td>0.345737</td>\n",
       "      <td>0.644437</td>\n",
       "      <td>23.677000</td>\n",
       "      <td>0.105923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-10</th>\n",
       "      <td>0.197982</td>\n",
       "      <td>0.348011</td>\n",
       "      <td>0.644437</td>\n",
       "      <td>55.709036</td>\n",
       "      <td>0.105923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>0.197982</td>\n",
       "      <td>0.348011</td>\n",
       "      <td>0.644437</td>\n",
       "      <td>55.709036</td>\n",
       "      <td>0.105923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.194652</td>\n",
       "      <td>0.345737</td>\n",
       "      <td>0.644437</td>\n",
       "      <td>23.677000</td>\n",
       "      <td>0.105923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.194497</td>\n",
       "      <td>0.345680</td>\n",
       "      <td>0.644437</td>\n",
       "      <td>23.425549</td>\n",
       "      <td>0.105923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.194652</td>\n",
       "      <td>0.345737</td>\n",
       "      <td>0.644437</td>\n",
       "      <td>23.677000</td>\n",
       "      <td>0.105923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.188439</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>0.644437</td>\n",
       "      <td>15.792466</td>\n",
       "      <td>0.105923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.085205</td>\n",
       "      <td>-0.076636</td>\n",
       "      <td>-0.085341</td>\n",
       "      <td>0.695386</td>\n",
       "      <td>0.105923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statistical_parity_difference  average_abs_odds_difference  \\\n",
       "1e-17                       0.194652                     0.345737   \n",
       "1e-10                       0.197982                     0.348011   \n",
       "0.001                       0.197982                     0.348011   \n",
       "0.01                        0.194652                     0.345737   \n",
       "0.1                         0.194497                     0.345680   \n",
       "0                           0.194652                     0.345737   \n",
       "1                           0.188439                     0.343284   \n",
       "5                          -0.085205                    -0.076636   \n",
       "10                          0.000000                     0.000000   \n",
       "25                          0.000000                     0.000000   \n",
       "50                          0.000000                     0.000000   \n",
       "100                         0.000000                     0.000000   \n",
       "\n",
       "       equal_opportunity_difference  disparate_impact  theil_index  \n",
       "1e-17                      0.644437         23.677000     0.105923  \n",
       "1e-10                      0.644437         55.709036     0.105923  \n",
       "0.001                      0.644437         55.709036     0.105923  \n",
       "0.01                       0.644437         23.677000     0.105923  \n",
       "0.1                        0.644437         23.425549     0.105923  \n",
       "0                          0.644437         23.677000     0.105923  \n",
       "1                          0.644437         15.792466     0.105923  \n",
       "5                         -0.085341          0.695386     0.105923  \n",
       "10                         0.000000          1.000000     0.000000  \n",
       "25                         0.000000          1.000000     0.000000  \n",
       "50                         0.000000          1.000000     0.000000  \n",
       "100                        0.000000          1.000000     0.000000  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics.to_json(\"./results/fairness_metrics_original_pdf.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "model.fit(X_train, y_train)\n",
    "probs = pd.Series(model.predict_proba(X_train)[:, 1]) # we select for target label\n",
    "\n",
    "df_probs_diff = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"count\",\n",
    "        \"expected_probability\",\n",
    "        \"model_probability\",\n",
    "    ]\n",
    ")\n",
    "for penalty, priv in priviliged_subsets.items():\n",
    "    df_probs_diff.loc[penalty] = calc_diff(df_train, probs, target, priv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>expected_probability</th>\n",
       "      <th>model_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1e-17</th>\n",
       "      <td>9829</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-10</th>\n",
       "      <td>9826</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>9826</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>60</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>382</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9829</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.5559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>203</td>\n",
       "      <td>0.4433</td>\n",
       "      <td>0.6139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  expected_probability  model_probability\n",
       "1e-17   9829                0.0095             0.0210\n",
       "1e-10   9826                0.0095             0.0210\n",
       "0.001   9826                0.0095             0.0210\n",
       "0.01      60                0.0667             0.4962\n",
       "0.1      382                0.0681             0.2038\n",
       "0       9829                0.0095             0.0210\n",
       "1         90                0.2222             0.5559\n",
       "5        203                0.4433             0.6139\n",
       "10         0                   NaN                NaN\n",
       "25         0                   NaN                NaN\n",
       "50         0                   NaN                NaN\n",
       "100        0                   NaN                NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_probs_diff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
