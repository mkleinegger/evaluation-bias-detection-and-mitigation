{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random_state = 12041500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_json(\"./data/synthetic_data_CTGANSynthesizer.json\")\n",
    "df_test = pd.read_json(\"./data/testset.json\")\n",
    "\n",
    "df_train.drop(columns=['fnlwgt'], inplace=True)\n",
    "df_test.drop(columns=['fnlwgt'], inplace=True)\n",
    "\n",
    "ratio_features = [\"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "ordinal_features = [\"education-num\"]\n",
    "nominal_features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex']\n",
    "target = 'income'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import create_model, train_and_evaluate, describe_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8361032716630082\n",
      "Precision      0.7822701965699763\n",
      "Recall         0.7458442654631545\n",
      "F1             0.7608356769787064\n"
     ]
    }
   ],
   "source": [
    "## Train baseline\n",
    "model = create_model(clf, nominal_features)\n",
    "y_test, y_pred = train_and_evaluate(model, df_train, df_test, target, drop_na=True)\n",
    "metrics = describe_model(y_test, y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split_data\n",
    "from utils_fairness import search_bias, calc_fairness_score, explain_detected_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_data(df_train, target, drop_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "model.fit(X_train, y_train)\n",
    "probs = pd.Series(model.predict_proba(X_train)[:, 1]) # we select for target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_subset, _ = search_bias(X_train, y_train, probs, 1, penalty=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'capital-gain': [0, 1, 6]}, 210.8649)\n"
     ]
    }
   ],
   "source": [
    "print(privileged_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive Attributes: ['capital-gain']\n",
      "\n",
      "                         Group Distance  Proportion  Counts   P-Value\n",
      "capital-gain [37.00, 16383.00]    0.434    0.095449    3563  0.00e+00\n",
      "    capital-gain [-0.00, 5.00]   -0.137    0.517078   19302 1.48e-323\n",
      "   capital-gain [23.00, 37.00]    0.253    0.097458    3638 3.41e-256\n",
      "   capital-gain [15.00, 23.00]    0.087    0.106352    3970  1.82e-38\n",
      "    capital-gain [5.00, 10.00]   -0.047    0.097645    3645  2.44e-13\n",
      "\n",
      "Weighted Mean Statistical Distance: 0.1648489023109496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fairlens.scorer.FairnessScorer at 0x15861a830>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_fairness_score(df_train, privileged_subset[0].keys(), target, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our detected privileged group has a size of 17732, we observe 0.0594 as the average probability of earning >50k, but our model predicts 0.2059\n"
     ]
    }
   ],
   "source": [
    "explain_detected_bias(df_train, probs, target, privileged_subset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_fairness import transform_to_bias_dataset, describe_fairness, scan_and_calculate_fairness, plot_fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744 Na rows removed!\n",
      "202 Na rows removed!\n"
     ]
    }
   ],
   "source": [
    "df_train_bias = transform_to_bias_dataset(df_train, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)\n",
    "df_test_bias = transform_to_bias_dataset(df_test, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.20866477995599425\n",
      "average_odds_difference         0.18045635399467233\n",
      "equal_opportunity_difference    0.2979438458132316\n",
      "disparate_impact                6.0227746607021\n",
      "theil_index                     0.11351788790247734\n"
     ]
    }
   ],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "y_test, y_pred = train_and_evaluate(model, df_train, df_train, target, drop_na=True)\n",
    "metrics = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics, priviliged_subsets = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"statistical_parity_difference\",\n",
    "        \"average_abs_odds_difference\",\n",
    "        \"equal_opportunity_difference\",\n",
    "        \"disparate_impact\",\n",
    "        \"theil_index\",\n",
    "    ]\n",
    "), {}\n",
    "\n",
    "for i in [1e-17, 1e-10, 0.001, 0.01, 0.1, 0, 1, 5, 10, 25, 50, 100]:\n",
    "    metrics, priv = scan_and_calculate_fairness(model, df_train, target, i)    \n",
    "    df_fairness_metrics.loc[f\"{i}\"] = metrics.values()\n",
    "    priviliged_subsets[f\"{i}\"] = priv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics.to_json(\"./results/fairness_metrics_synthetic.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn import clone\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from utils_fairness import create_aif360_standardDataset, compute_metrics, reweight_mitigation\n",
    "from utils import plot_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create (un)privileged groups\n",
    "privileged_groups = [{key: 1 for key in list(privileged_subset[0].keys())}]\n",
    "unprivileged_groups = [{key: 0 for key in list(privileged_subset[0].keys())}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset\n",
    "train_dataset = create_aif360_standardDataset(df_train.dropna(), nominal_features, target, 1, list(privileged_subset[0].keys()), list(privileged_subset[0].values()))\n",
    "test_dataset = create_aif360_standardDataset(df_test.dropna(), nominal_features, target, 1, list(privileged_subset[0].keys()), list(privileged_subset[0].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "RW.fit(train_dataset)\n",
    "\n",
    "train_dataset_reweight = RW.transform(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8250235183443085\n",
      "Precision      0.8011300969157298\n",
      "Recall         0.6760386016778689\n",
      "F1             0.7049576572819011\n"
     ]
    }
   ],
   "source": [
    "model = clone(clf)\n",
    "model.fit(train_dataset.features, train_dataset.labels.ravel())\n",
    "y_pred = model.predict(test_dataset.features)\n",
    "\n",
    "_ = describe_model(test_dataset.labels.ravel(), y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.27325293449977367\n",
      "average_odds_difference         0.3160490306583643\n",
      "equal_opportunity_difference    0.5220668823049727\n",
      "disparate_impact                20.055737563922488\n",
      "theil_index                     0.10899556247160261\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(train_dataset.features)\n",
    "_ = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mitigated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8145709208738372\n",
      "Precision      0.7467964552505164\n",
      "Recall         0.7586925908420961\n",
      "F1             0.752294520368006\n"
     ]
    }
   ],
   "source": [
    "# mitigated model\n",
    "model = clone(clf)\n",
    "model.fit(train_dataset_reweight.features, train_dataset_reweight.labels.ravel(), sample_weight=train_dataset_reweight.instance_weights)\n",
    "y_pred = model.predict(test_dataset.features)\n",
    "\n",
    "_ = describe_model(test_dataset.labels.ravel(), y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.10227744846927242\n",
      "average_odds_difference         -0.005485384858981368\n",
      "equal_opportunity_difference    -0.005484955838945593\n",
      "disparate_impact                2.198612477012649\n",
      "theil_index                     0.1333673780742846\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(train_dataset.features)\n",
    "_ = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias detection & mitigation until bias free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"statistical_parity_difference\",\n",
    "        \"average_abs_odds_difference\",\n",
    "        \"equal_opportunity_difference\",\n",
    "        \"disparate_impact\",\n",
    "        \"theil_index\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(\n",
    "    columns=['acc', 'prec', 'rec', 'f1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = None\n",
    "\n",
    "weights_hist = [weights]\n",
    "max_iter = 10\n",
    "for i in tqdm(range(max_iter)):\n",
    "    X_train, y_train = split_data(df_train, target, True)\n",
    "    X_test, y_test = split_data(df_test, target, True)\n",
    "    weights, model_metrics, fair_metrics = reweight_mitigation(clf, nominal_features, target, X_train, y_train, X_test, y_test, penalty=1, sample_weights=weights)\n",
    "    if model_metrics is None and fair_metrics is None and weights is None:\n",
    "        break\n",
    "\n",
    "    df_metrics.loc[f\"mitigation_{i}\"] = model_metrics.values()\n",
    "    df_fairness_metrics.loc[f\"mitigation_{i}\"] = fair_metrics.values()\n",
    "    weights_hist.append(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prepare_data_fair_learning, plot_fairlearning_results\n",
    "from utils_fairness import get_fair_learning_scoring\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from aif360.sklearn.preprocessing import LearnedFairRepresentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744 Na rows removed!\n",
      "202 Na rows removed!\n"
     ]
    }
   ],
   "source": [
    "df_train_bias = transform_to_bias_dataset(df_train, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)\n",
    "df_test_bias = transform_to_bias_dataset(df_test, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)\n",
    "\n",
    "X_train, y_train, X_test, y_test = prepare_data_fair_learning(df_train_bias, df_test_bias, nominal_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_delta = get_fair_learning_scoring(list(privileged_subset[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfr = LearnedFairRepresentations(\n",
    "    list(privileged_subset[0].keys()),\n",
    "    n_prototypes=25,\n",
    "    max_iter=100,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"reconstruct_weight\": [1e-2, 1e-3, 1e-4],\n",
    "    \"target_weight\": [100, 1000],\n",
    "    \"fairness_weight\": [0, 100, 1000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(lfr, params, scoring=max_delta, cv=3, n_jobs=-1).fit(\n",
    "    X_train, y_train, priv_group=(1,) * len(list(privileged_subset[0].keys()))\n",
    ")\n",
    "res = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8368349534859413\n",
      "Precision      0.7828137452198869\n",
      "Recall         0.7485532086541198\n",
      "F1             0.7628348756731729\n"
     ]
    }
   ],
   "source": [
    "model = clone(clf)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "_ = describe_model(y_test, y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.20656582123293724\n",
      "average_odds_difference         0.1795749894343781\n",
      "equal_opportunity_difference    0.2977239135212729\n",
      "disparate_impact                6.014991986552083\n",
      "theil_index                     0.11421882144989567\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "_ = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Grid itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.7742238946378175\n",
      "Precision      0.6846828630086876\n",
      "Recall         0.5927048197548834\n",
      "F1             0.6024177943160193\n"
     ]
    }
   ],
   "source": [
    "_ = describe_model(y_test, grid.predict(X_test), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.2776604056164877\n",
      "average_odds_difference         0.3444513447318348\n",
      "equal_opportunity_difference    0.5376897044397566\n",
      "disparate_impact                277.7784255045295\n",
      "theil_index                     0.13564518741647613\n"
     ]
    }
   ],
   "source": [
    "_ = describe_fairness(y_train, grid.predict(X_train), list(privileged_subset[0].keys()) ,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.7765234660813212\n",
      "Precision      0.697120770494787\n",
      "Recall         0.5827855156502163\n",
      "F1             0.588704481752163\n"
     ]
    }
   ],
   "source": [
    "model = clone(clf)\n",
    "model.fit(grid.transform(X_train), y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "_ = describe_model(y_test, y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.09807192268066527\n",
      "average_odds_difference         0.11742834217467112\n",
      "equal_opportunity_difference    0.1723249469536223\n",
      "disparate_impact                            0.0\n",
      "theil_index                     0.2012487441489287\n"
     ]
    }
   ],
   "source": [
    "_ = describe_fairness(y_train, model.predict(X_train), list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Also Transforming test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.7754782063342741\n",
      "Precision      0.6889270638844567\n",
      "Recall         0.5918972686632136\n",
      "F1             0.6013375712648379\n"
     ]
    }
   ],
   "source": [
    "_ = describe_model(y_test, model.predict(grid.transform(X_test)), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.2961085343142529\n",
      "average_odds_difference         0.36685438686235855\n",
      "equal_opportunity_difference    0.5702411508430346\n",
      "disparate_impact                717.8364603556184\n",
      "theil_index                     0.13084895074813588\n"
     ]
    }
   ],
   "source": [
    "_ = describe_fairness(y_train, model.predict(grid.transform(X_train)), list(privileged_subset[0].keys()) ,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Runs cannot be done, because of the dataset already needs to be one hot encoded for the mitigation, making the `search_bias` function unnecessary and returning not viable resolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_fairness_weight</th>\n",
       "      <th>param_reconstruct_weight</th>\n",
       "      <th>param_target_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.752142</td>\n",
       "      <td>1.777984</td>\n",
       "      <td>0.112692</td>\n",
       "      <td>0.072171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fairness_weight': 0, 'reconstruct_weight': 0...</td>\n",
       "      <td>-0.703722</td>\n",
       "      <td>-0.744387</td>\n",
       "      <td>-0.764539</td>\n",
       "      <td>-0.737549</td>\n",
       "      <td>0.025295</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.338813</td>\n",
       "      <td>0.354392</td>\n",
       "      <td>0.100726</td>\n",
       "      <td>0.010804</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'fairness_weight': 0, 'reconstruct_weight': 0...</td>\n",
       "      <td>-0.569532</td>\n",
       "      <td>-0.609017</td>\n",
       "      <td>-0.432301</td>\n",
       "      <td>-0.536950</td>\n",
       "      <td>0.075733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.814898</td>\n",
       "      <td>5.863008</td>\n",
       "      <td>0.096248</td>\n",
       "      <td>0.014033</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fairness_weight': 0, 'reconstruct_weight': 0...</td>\n",
       "      <td>-0.565238</td>\n",
       "      <td>-0.620270</td>\n",
       "      <td>-0.525844</td>\n",
       "      <td>-0.570451</td>\n",
       "      <td>0.038725</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.801443</td>\n",
       "      <td>1.672079</td>\n",
       "      <td>0.107203</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'fairness_weight': 0, 'reconstruct_weight': 0...</td>\n",
       "      <td>-0.568084</td>\n",
       "      <td>-0.574992</td>\n",
       "      <td>-0.542222</td>\n",
       "      <td>-0.561766</td>\n",
       "      <td>0.014104</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.644145</td>\n",
       "      <td>0.481360</td>\n",
       "      <td>0.071161</td>\n",
       "      <td>0.021377</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fairness_weight': 0, 'reconstruct_weight': 0...</td>\n",
       "      <td>-0.556896</td>\n",
       "      <td>-0.566217</td>\n",
       "      <td>-0.548289</td>\n",
       "      <td>-0.557134</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.326477</td>\n",
       "      <td>0.717361</td>\n",
       "      <td>0.102469</td>\n",
       "      <td>0.077344</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'fairness_weight': 0, 'reconstruct_weight': 0...</td>\n",
       "      <td>-0.588357</td>\n",
       "      <td>-0.496911</td>\n",
       "      <td>-0.560892</td>\n",
       "      <td>-0.548720</td>\n",
       "      <td>0.038312</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21.813466</td>\n",
       "      <td>1.790828</td>\n",
       "      <td>0.082802</td>\n",
       "      <td>0.021522</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fairness_weight': 100, 'reconstruct_weight':...</td>\n",
       "      <td>-0.763504</td>\n",
       "      <td>-0.762012</td>\n",
       "      <td>-0.706881</td>\n",
       "      <td>-0.744132</td>\n",
       "      <td>0.026348</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.207369</td>\n",
       "      <td>0.919578</td>\n",
       "      <td>0.135667</td>\n",
       "      <td>0.058018</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'fairness_weight': 100, 'reconstruct_weight':...</td>\n",
       "      <td>-0.689450</td>\n",
       "      <td>-0.601783</td>\n",
       "      <td>-0.476128</td>\n",
       "      <td>-0.589120</td>\n",
       "      <td>0.087548</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17.000117</td>\n",
       "      <td>0.234587</td>\n",
       "      <td>0.048463</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fairness_weight': 100, 'reconstruct_weight':...</td>\n",
       "      <td>-0.585105</td>\n",
       "      <td>-0.568125</td>\n",
       "      <td>-0.570999</td>\n",
       "      <td>-0.574743</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.885579</td>\n",
       "      <td>1.262007</td>\n",
       "      <td>0.052776</td>\n",
       "      <td>0.018838</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'fairness_weight': 100, 'reconstruct_weight':...</td>\n",
       "      <td>-0.594535</td>\n",
       "      <td>-0.587861</td>\n",
       "      <td>-0.481526</td>\n",
       "      <td>-0.554640</td>\n",
       "      <td>0.051772</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.322179</td>\n",
       "      <td>3.661387</td>\n",
       "      <td>0.039818</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fairness_weight': 100, 'reconstruct_weight':...</td>\n",
       "      <td>-0.576159</td>\n",
       "      <td>-0.564105</td>\n",
       "      <td>-0.576361</td>\n",
       "      <td>-0.572208</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.840090</td>\n",
       "      <td>0.387408</td>\n",
       "      <td>0.051696</td>\n",
       "      <td>0.012353</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'fairness_weight': 100, 'reconstruct_weight':...</td>\n",
       "      <td>-0.562867</td>\n",
       "      <td>-0.577412</td>\n",
       "      <td>-0.490997</td>\n",
       "      <td>-0.543759</td>\n",
       "      <td>0.037778</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.250508</td>\n",
       "      <td>3.409876</td>\n",
       "      <td>0.049781</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fairness_weight': 1000, 'reconstruct_weight'...</td>\n",
       "      <td>-0.795628</td>\n",
       "      <td>-0.795548</td>\n",
       "      <td>-0.795548</td>\n",
       "      <td>-0.795574</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.841731</td>\n",
       "      <td>1.262712</td>\n",
       "      <td>0.076095</td>\n",
       "      <td>0.037868</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'fairness_weight': 1000, 'reconstruct_weight'...</td>\n",
       "      <td>-0.564826</td>\n",
       "      <td>-0.574573</td>\n",
       "      <td>-0.624219</td>\n",
       "      <td>-0.587873</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.348734</td>\n",
       "      <td>1.339395</td>\n",
       "      <td>0.211093</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fairness_weight': 1000, 'reconstruct_weight'...</td>\n",
       "      <td>-0.795628</td>\n",
       "      <td>-0.795548</td>\n",
       "      <td>-0.795548</td>\n",
       "      <td>-0.795574</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.102984</td>\n",
       "      <td>1.602492</td>\n",
       "      <td>0.110720</td>\n",
       "      <td>0.040254</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'fairness_weight': 1000, 'reconstruct_weight'...</td>\n",
       "      <td>-0.567570</td>\n",
       "      <td>-0.582144</td>\n",
       "      <td>-0.660412</td>\n",
       "      <td>-0.603375</td>\n",
       "      <td>0.040767</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.345617</td>\n",
       "      <td>0.767558</td>\n",
       "      <td>0.023439</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fairness_weight': 1000, 'reconstruct_weight'...</td>\n",
       "      <td>-0.795628</td>\n",
       "      <td>-0.795548</td>\n",
       "      <td>-0.795548</td>\n",
       "      <td>-0.795574</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11.618525</td>\n",
       "      <td>2.108769</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'fairness_weight': 1000, 'reconstruct_weight'...</td>\n",
       "      <td>-0.585564</td>\n",
       "      <td>-0.591474</td>\n",
       "      <td>-0.586374</td>\n",
       "      <td>-0.587804</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       24.752142      1.777984         0.112692        0.072171   \n",
       "1       19.338813      0.354392         0.100726        0.010804   \n",
       "2       14.814898      5.863008         0.096248        0.014033   \n",
       "3       18.801443      1.672079         0.107203        0.017980   \n",
       "4       19.644145      0.481360         0.071161        0.021377   \n",
       "5       19.326477      0.717361         0.102469        0.077344   \n",
       "6       21.813466      1.790828         0.082802        0.021522   \n",
       "7       16.207369      0.919578         0.135667        0.058018   \n",
       "8       17.000117      0.234587         0.048463        0.008176   \n",
       "9       15.885579      1.262007         0.052776        0.018838   \n",
       "10      14.322179      3.661387         0.039818        0.003150   \n",
       "11      10.840090      0.387408         0.051696        0.012353   \n",
       "12      13.250508      3.409876         0.049781        0.031338   \n",
       "13      13.841731      1.262712         0.076095        0.037868   \n",
       "14      20.348734      1.339395         0.211093        0.128186   \n",
       "15      15.102984      1.602492         0.110720        0.040254   \n",
       "16      15.345617      0.767558         0.023439        0.004901   \n",
       "17      11.618525      2.108769         0.015385        0.000675   \n",
       "\n",
       "    param_fairness_weight  param_reconstruct_weight  param_target_weight  \\\n",
       "0                       0                    0.0100                  100   \n",
       "1                       0                    0.0100                 1000   \n",
       "2                       0                    0.0010                  100   \n",
       "3                       0                    0.0010                 1000   \n",
       "4                       0                    0.0001                  100   \n",
       "5                       0                    0.0001                 1000   \n",
       "6                     100                    0.0100                  100   \n",
       "7                     100                    0.0100                 1000   \n",
       "8                     100                    0.0010                  100   \n",
       "9                     100                    0.0010                 1000   \n",
       "10                    100                    0.0001                  100   \n",
       "11                    100                    0.0001                 1000   \n",
       "12                   1000                    0.0100                  100   \n",
       "13                   1000                    0.0100                 1000   \n",
       "14                   1000                    0.0010                  100   \n",
       "15                   1000                    0.0010                 1000   \n",
       "16                   1000                    0.0001                  100   \n",
       "17                   1000                    0.0001                 1000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'fairness_weight': 0, 'reconstruct_weight': 0...          -0.703722   \n",
       "1   {'fairness_weight': 0, 'reconstruct_weight': 0...          -0.569532   \n",
       "2   {'fairness_weight': 0, 'reconstruct_weight': 0...          -0.565238   \n",
       "3   {'fairness_weight': 0, 'reconstruct_weight': 0...          -0.568084   \n",
       "4   {'fairness_weight': 0, 'reconstruct_weight': 0...          -0.556896   \n",
       "5   {'fairness_weight': 0, 'reconstruct_weight': 0...          -0.588357   \n",
       "6   {'fairness_weight': 100, 'reconstruct_weight':...          -0.763504   \n",
       "7   {'fairness_weight': 100, 'reconstruct_weight':...          -0.689450   \n",
       "8   {'fairness_weight': 100, 'reconstruct_weight':...          -0.585105   \n",
       "9   {'fairness_weight': 100, 'reconstruct_weight':...          -0.594535   \n",
       "10  {'fairness_weight': 100, 'reconstruct_weight':...          -0.576159   \n",
       "11  {'fairness_weight': 100, 'reconstruct_weight':...          -0.562867   \n",
       "12  {'fairness_weight': 1000, 'reconstruct_weight'...          -0.795628   \n",
       "13  {'fairness_weight': 1000, 'reconstruct_weight'...          -0.564826   \n",
       "14  {'fairness_weight': 1000, 'reconstruct_weight'...          -0.795628   \n",
       "15  {'fairness_weight': 1000, 'reconstruct_weight'...          -0.567570   \n",
       "16  {'fairness_weight': 1000, 'reconstruct_weight'...          -0.795628   \n",
       "17  {'fairness_weight': 1000, 'reconstruct_weight'...          -0.585564   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           -0.744387          -0.764539        -0.737549        0.025295   \n",
       "1           -0.609017          -0.432301        -0.536950        0.075733   \n",
       "2           -0.620270          -0.525844        -0.570451        0.038725   \n",
       "3           -0.574992          -0.542222        -0.561766        0.014104   \n",
       "4           -0.566217          -0.548289        -0.557134        0.007321   \n",
       "5           -0.496911          -0.560892        -0.548720        0.038312   \n",
       "6           -0.762012          -0.706881        -0.744132        0.026348   \n",
       "7           -0.601783          -0.476128        -0.589120        0.087548   \n",
       "8           -0.568125          -0.570999        -0.574743        0.007421   \n",
       "9           -0.587861          -0.481526        -0.554640        0.051772   \n",
       "10          -0.564105          -0.576361        -0.572208        0.005731   \n",
       "11          -0.577412          -0.490997        -0.543759        0.037778   \n",
       "12          -0.795548          -0.795548        -0.795574        0.000038   \n",
       "13          -0.574573          -0.624219        -0.587873        0.026007   \n",
       "14          -0.795548          -0.795548        -0.795574        0.000038   \n",
       "15          -0.582144          -0.660412        -0.603375        0.040767   \n",
       "16          -0.795548          -0.795548        -0.795574        0.000038   \n",
       "17          -0.591474          -0.586374        -0.587804        0.002616   \n",
       "\n",
       "    rank_test_score  \n",
       "0                14  \n",
       "1                 1  \n",
       "2                 7  \n",
       "3                 6  \n",
       "4                 5  \n",
       "5                 3  \n",
       "6                15  \n",
       "7                12  \n",
       "8                 9  \n",
       "9                 4  \n",
       "10                8  \n",
       "11                2  \n",
       "12               16  \n",
       "13               11  \n",
       "14               16  \n",
       "15               13  \n",
       "16               16  \n",
       "17               10  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils_fairness import create_aif360_standardDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create (un)privileged groups\n",
    "privileged_groups = [{key: 1 for key in list(privileged_subset[0].keys())}]\n",
    "unprivileged_groups = [{key: 0 for key in list(privileged_subset[0].keys())}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fairness_weight': 0, 'reconstruct_weight': 0.01, 'target_weight': 1000}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 693.9774324818318, L_x: 4050.095772408544,  L_y: 0.6534764747577464,  L_z: 0.0014173912912793184\n",
      "step: 250, loss: 693.9774319689096, L_x: 4050.0957723490305,  L_y: 0.6534764742454193,  L_z: 0.0014173919018108771\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          250     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.93977D+02    |proj g|=  2.98246D+01\n",
      "step: 500, loss: 640.1850574596295, L_x: 4049.176292285174,  L_y: 0.5996932945367778,  L_z: 0.0009651204130496499\n",
      "\n",
      "At iterate    1    f=  6.40185D+02    |proj g|=  2.11041D+01\n",
      "step: 750, loss: 608.5644683903249, L_x: 4042.221310598115,  L_y: 0.5681422552843437,  L_z: 0.001024285487798589\n",
      "step: 1000, loss: 577.2502664616709, L_x: 4047.420010606822,  L_y: 0.5367760663556027,  L_z: 0.0007042036313121586\n",
      "\n",
      "At iterate    2    f=  5.77250D+02    |proj g|=  1.78881D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  250      2      4      7     0     0   1.789D+01   5.773D+02\n",
      "  F =   577.25026242824390     \n",
      "\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT        \n"
     ]
    }
   ],
   "source": [
    "TR = LFR(unprivileged_groups=unprivileged_groups,\n",
    "         privileged_groups=privileged_groups,\n",
    "         k=5, Ax=0.01, Ay=1000, Az=0,\n",
    "         verbose=1,\n",
    "         seed=random_state\n",
    ")\n",
    "\n",
    "TR = TR.fit(train_dataset, maxiter=5000, maxfun=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training data and align features\n",
    "train_dataset_lfr = TR.transform(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 37329}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = {}\n",
    "for i in dataset_transf_train.labels.ravel():\n",
    "    cnt[i] = cnt.get(i, 0) + 1\n",
    "\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.8250235183443085\n",
      "Precision      0.8011300969157298\n",
      "Recall         0.6760386016778689\n",
      "F1             0.7049576572819011\n"
     ]
    }
   ],
   "source": [
    "model = clone(clf)\n",
    "model.fit(train_dataset.features, train_dataset.labels.ravel())\n",
    "y_pred = model.predict(test_dataset.features)\n",
    "\n",
    "_ = describe_model(test_dataset.labels.ravel(), y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.27325293449977367\n",
      "average_odds_difference         0.3160490306583643\n",
      "equal_opportunity_difference    0.5220668823049727\n",
      "disparate_impact                20.055737563922488\n",
      "theil_index                     0.10899556247160261\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(train_dataset.features)\n",
    "_ = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.7594857322044528\n",
      "Precision      0.3797428661022264\n",
      "Recall                     0.5\n",
      "F1             0.4316521119230084\n"
     ]
    }
   ],
   "source": [
    "_ = describe_model(df_test_bias[target], [0]*len(df_test_bias[target]), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference               0.0\n",
      "average_odds_difference                     0.0\n",
      "equal_opportunity_difference                0.0\n",
      "disparate_impact                            0.0\n",
      "theil_index                     0.22869080098773423\n"
     ]
    }
   ],
   "source": [
    "_ = describe_fairness(df_train_bias[target], np.array([0]*len(df_train_bias)), list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disparate Impact Remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = train_dataset.feature_names.index('capital-gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:49<00:00,  9.81s/it]\n"
     ]
    }
   ],
   "source": [
    "fairness_metrics = []\n",
    "utility_metrics = []\n",
    "for level in tqdm(np.linspace(0, 1, 10)):\n",
    "    di = DisparateImpactRemover(repair_level=level)\n",
    "    train_repd = di.fit_transform(train_dataset)\n",
    "    test_repd = di.fit_transform(test_dataset)\n",
    "    \n",
    "    X_tr = np.delete(train_repd.features, index, axis=1)\n",
    "    X_te = np.delete(test_repd.features, index, axis=1)\n",
    "    y_tr = train_repd.labels.ravel()\n",
    "    \n",
    "    model = clone(clf)\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    utility_metrics.append(describe_model(test_repd.labels.ravel(), model.predict(X_te), verbose=False))\n",
    "    fairness_metrics.append(describe_fairness(df_train_bias[target], model.predict(X_tr), list(privileged_subset[0].keys()), verbose=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
