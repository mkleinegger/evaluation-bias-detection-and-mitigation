{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random_state = 12041500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_json(\"./data/synthetic_data_CTGANSynthesizer.json\")\n",
    "df_test = pd.read_json(\"./data/testset.json\")\n",
    "\n",
    "df_train.drop(columns=['fnlwgt'], inplace=True)\n",
    "df_test.drop(columns=['fnlwgt'], inplace=True)\n",
    "\n",
    "ratio_features = [\"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "ordinal_features = [\"education-num\"]\n",
    "nominal_features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex']\n",
    "target = 'income'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import create_model, train_and_evaluate, describe_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.836\n",
      "Precision      0.782\n",
      "Recall         0.746\n",
      "F1             0.761\n"
     ]
    }
   ],
   "source": [
    "## Train baseline\n",
    "model = create_model(clf, nominal_features)\n",
    "y_test, y_pred = train_and_evaluate(model, df_train, df_test, target, drop_na=True)\n",
    "metrics = describe_model(y_test, y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split_data\n",
    "from utils_fairness import search_bias, calc_fairness_score, explain_detected_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_data(df_train, target, drop_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "model.fit(X_train, y_train)\n",
    "probs = pd.Series(model.predict_proba(X_train)[:, 1]) # we select for target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_subset, _ = search_bias(X_train, y_train, probs, 1, penalty=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'capital-gain': [0, 1, 4, 5, 6]}, 226.8525)\n"
     ]
    }
   ],
   "source": [
    "print(privileged_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive Attributes: ['capital-gain']\n",
      "\n",
      "                         Group Distance  Proportion  Counts   P-Value\n",
      "capital-gain [37.00, 16383.00]    0.434    0.095449    3563  0.00e+00\n",
      "    capital-gain [-0.00, 5.00]   -0.137    0.517078   19302 1.48e-323\n",
      "   capital-gain [23.00, 37.00]    0.253    0.097458    3638 3.41e-256\n",
      "   capital-gain [15.00, 23.00]    0.087    0.106352    3970  1.82e-38\n",
      "    capital-gain [5.00, 10.00]   -0.047    0.097645    3645  2.44e-13\n",
      "\n",
      "Weighted Mean Statistical Distance: 0.1648489023109496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fairlens.scorer.FairnessScorer at 0x10c357ee0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_fairness_score(df_train, privileged_subset[0].keys(), target, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our detected privileged group has a size of 19340, we observe 0.0639 as the average probability of earning >50k, but our model predicts 0.2058\n"
     ]
    }
   ],
   "source": [
    "explain_detected_bias(df_train, probs, target, privileged_subset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_fairness import transform_to_bias_dataset, describe_fairness, scan_and_calculate_fairness, plot_fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744 Na rows removed!\n",
      "202 Na rows removed!\n"
     ]
    }
   ],
   "source": [
    "df_train_bias = transform_to_bias_dataset(df_train, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)\n",
    "df_test_bias = transform_to_bias_dataset(df_test, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.220\n",
      "average_odds_difference         0.182\n",
      "equal_opportunity_difference    0.297\n",
      "disparate_impact                5.949\n",
      "theil_index                     0.114\n"
     ]
    }
   ],
   "source": [
    "model = create_model(clf, nominal_features)\n",
    "y_test, y_pred = train_and_evaluate(model, df_train, df_train, target, drop_na=True)\n",
    "metrics = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics, priviliged_subsets = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"statistical_parity_difference\",\n",
    "        \"average_abs_odds_difference\",\n",
    "        \"equal_opportunity_difference\",\n",
    "        \"disparate_impact\",\n",
    "        \"theil_index\",\n",
    "    ]\n",
    "), {}\n",
    "\n",
    "for i in [1e-17, 1e-10, 0.001, 0.01, 0.1, 0, 1, 5, 10, 25, 50, 100]:\n",
    "    metrics, priv = scan_and_calculate_fairness(model, df_train, target, i)    \n",
    "    df_fairness_metrics.loc[f\"{i}\"] = metrics.values()\n",
    "    priviliged_subsets[f\"{i}\"] = priv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <th>average_abs_odds_difference</th>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>theil_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1e-17</th>\n",
       "      <td>0.157790</td>\n",
       "      <td>0.301264</td>\n",
       "      <td>0.548028</td>\n",
       "      <td>80.920614</td>\n",
       "      <td>0.113518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-10</th>\n",
       "      <td>0.176903</td>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.245121</td>\n",
       "      <td>4.778996</td>\n",
       "      <td>0.113518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>-0.072405</td>\n",
       "      <td>-0.190094</td>\n",
       "      <td>-0.251483</td>\n",
       "      <td>0.678597</td>\n",
       "      <td>0.113518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.106165</td>\n",
       "      <td>0.276341</td>\n",
       "      <td>0.548028</td>\n",
       "      <td>3.123298</td>\n",
       "      <td>0.113518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.164673</td>\n",
       "      <td>0.148689</td>\n",
       "      <td>0.262768</td>\n",
       "      <td>4.440570</td>\n",
       "      <td>0.113518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.157790</td>\n",
       "      <td>0.301264</td>\n",
       "      <td>0.548028</td>\n",
       "      <td>80.920614</td>\n",
       "      <td>0.113518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.219782</td>\n",
       "      <td>0.182051</td>\n",
       "      <td>0.297375</td>\n",
       "      <td>5.948852</td>\n",
       "      <td>0.113518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.208665</td>\n",
       "      <td>0.180456</td>\n",
       "      <td>0.297944</td>\n",
       "      <td>6.022775</td>\n",
       "      <td>0.113518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.201300</td>\n",
       "      <td>0.189152</td>\n",
       "      <td>0.317138</td>\n",
       "      <td>6.455366</td>\n",
       "      <td>0.113518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.201300</td>\n",
       "      <td>0.189152</td>\n",
       "      <td>0.317138</td>\n",
       "      <td>6.455366</td>\n",
       "      <td>0.113518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.201300</td>\n",
       "      <td>0.189152</td>\n",
       "      <td>0.317138</td>\n",
       "      <td>6.455366</td>\n",
       "      <td>0.113518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.201300</td>\n",
       "      <td>0.189152</td>\n",
       "      <td>0.317138</td>\n",
       "      <td>6.455366</td>\n",
       "      <td>0.113518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statistical_parity_difference  average_abs_odds_difference  \\\n",
       "1e-17                       0.157790                     0.301264   \n",
       "1e-10                       0.176903                     0.143317   \n",
       "0.001                      -0.072405                    -0.190094   \n",
       "0.01                        0.106165                     0.276341   \n",
       "0.1                         0.164673                     0.148689   \n",
       "0                           0.157790                     0.301264   \n",
       "1                           0.219782                     0.182051   \n",
       "5                           0.208665                     0.180456   \n",
       "10                          0.201300                     0.189152   \n",
       "25                          0.201300                     0.189152   \n",
       "50                          0.201300                     0.189152   \n",
       "100                         0.201300                     0.189152   \n",
       "\n",
       "       equal_opportunity_difference  disparate_impact  theil_index  \n",
       "1e-17                      0.548028         80.920614     0.113518  \n",
       "1e-10                      0.245121          4.778996     0.113518  \n",
       "0.001                     -0.251483          0.678597     0.113518  \n",
       "0.01                       0.548028          3.123298     0.113518  \n",
       "0.1                        0.262768          4.440570     0.113518  \n",
       "0                          0.548028         80.920614     0.113518  \n",
       "1                          0.297375          5.948852     0.113518  \n",
       "5                          0.297944          6.022775     0.113518  \n",
       "10                         0.317138          6.455366     0.113518  \n",
       "25                         0.317138          6.455366     0.113518  \n",
       "50                         0.317138          6.455366     0.113518  \n",
       "100                        0.317138          6.455366     0.113518  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics.to_json(\"./results/fairness_metrics_synthetic.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn import clone\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from utils_fairness import create_aif360_standardDataset, compute_metrics, reweight_mitigation\n",
    "from utils import plot_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create (un)privileged groups\n",
    "privileged_groups = [{key: 1 for key in list(privileged_subset[0].keys())}]\n",
    "unprivileged_groups = [{key: 0 for key in list(privileged_subset[0].keys())}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset\n",
    "train_dataset = create_aif360_standardDataset(df_train.dropna(), nominal_features, target, 1, list(privileged_subset[0].keys()), list(privileged_subset[0].values()))\n",
    "test_dataset = create_aif360_standardDataset(df_test.dropna(), nominal_features, target, 1, list(privileged_subset[0].keys()), list(privileged_subset[0].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "RW.fit(train_dataset)\n",
    "\n",
    "train_dataset_reweight = RW.transform(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.826\n",
      "Precision      0.801\n",
      "Recall         0.680\n",
      "F1             0.710\n"
     ]
    }
   ],
   "source": [
    "model = clone(clf)\n",
    "model.fit(train_dataset.features, train_dataset.labels.ravel())\n",
    "y_pred = model.predict(test_dataset.features)\n",
    "\n",
    "_ = describe_model(test_dataset.labels.ravel(), y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.294\n",
      "average_odds_difference         0.326\n",
      "equal_opportunity_difference    0.533\n",
      "disparate_impact                19.095\n",
      "theil_index                     0.108\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(train_dataset.features)\n",
    "_ = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mitigated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.815\n",
      "Precision      0.747\n",
      "Recall         0.754\n",
      "F1             0.750\n"
     ]
    }
   ],
   "source": [
    "# mitigated model\n",
    "model = clone(clf)\n",
    "model.fit(train_dataset_reweight.features, train_dataset_reweight.labels.ravel(), sample_weight=train_dataset_reweight.instance_weights)\n",
    "y_pred = model.predict(test_dataset.features)\n",
    "\n",
    "_ = describe_model(test_dataset.labels.ravel(), y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.107\n",
      "average_odds_difference         -0.002\n",
      "equal_opportunity_difference    0.002\n",
      "disparate_impact                2.234\n",
      "theil_index                     0.134\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(train_dataset.features)\n",
    "_ = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias detection & mitigation until bias free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairness_metrics = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"statistical_parity_difference\",\n",
    "        \"average_abs_odds_difference\",\n",
    "        \"equal_opportunity_difference\",\n",
    "        \"disparate_impact\",\n",
    "        \"theil_index\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(\n",
    "    columns=['acc', 'prec', 'rec', 'f1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [12:12<00:00, 29.30s/it]\n"
     ]
    }
   ],
   "source": [
    "weights = None\n",
    "\n",
    "weights_hist = [weights]\n",
    "max_iter = 25\n",
    "for i in tqdm(range(max_iter)):\n",
    "    X_train, y_train = split_data(df_train, target, True)\n",
    "    X_test, y_test = split_data(df_test, target, True)\n",
    "    weights, model_metrics, fair_metrics = reweight_mitigation(clf, nominal_features, target, X_train, y_train, X_test, y_test, penalty=1, sample_weights=weights)\n",
    "    if model_metrics is None and fair_metrics is None and weights is None:\n",
    "        break\n",
    "\n",
    "    df_metrics.loc[f\"mitigation_{i}\"] = model_metrics.values()\n",
    "    df_fairness_metrics.loc[f\"mitigation_{i}\"] = fair_metrics.values()\n",
    "    weights_hist.append(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_metrics_json = df_fairness_metrics.to_json(path_or_buf=\"./results/fairness_metrics_25_iterations_synthetic.json\")\n",
    "metrics_json = df_metrics.to_json(path_or_buf=\"./results/utility_metrics_25_iterations_synthetic.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prepare_data_fair_learning, plot_fairlearning_results\n",
    "from utils_fairness import get_fair_learning_scoring\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from aif360.sklearn.preprocessing import LearnedFairRepresentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744 Na rows removed!\n",
      "202 Na rows removed!\n"
     ]
    }
   ],
   "source": [
    "df_train_bias = transform_to_bias_dataset(df_train, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)\n",
    "df_test_bias = transform_to_bias_dataset(df_test, list(privileged_subset[0].keys()), list(privileged_subset[0].values()), verbose=True)\n",
    "\n",
    "X_train, y_train, X_test, y_test = prepare_data_fair_learning(df_train_bias, df_test_bias, nominal_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['capital-gain'] = X_train.index\n",
    "X_test['capital-gain'] = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_delta = get_fair_learning_scoring(list(privileged_subset[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfr = LearnedFairRepresentations(\n",
    "    list(privileged_subset[0].keys()),\n",
    "    n_prototypes=20,\n",
    "    max_iter=50,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"reconstruct_weight\": [1e-2, 1e-3, 1e-4],\n",
    "    \"target_weight\": [100, 1000],\n",
    "    \"fairness_weight\": [0, 100, 1000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n",
      "/Users/maxkleinegger/Documents/TUWien/2023WS/BA/.ba-thesis/lib/python3.10/site-packages/aif360/sklearn/preprocessing/learning_fair_representations.py:163: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn('lbfgs failed to converge. Increase the number of '\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(lfr, params, scoring=max_delta, cv=3, n_jobs=-1).fit(\n",
    "    X_train, y_train, priv_group=(1,) * len(list(privileged_subset[0].keys()))\n",
    ")\n",
    "res = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.827\n",
      "Precision      0.802\n",
      "Recall         0.682\n",
      "F1             0.711\n"
     ]
    }
   ],
   "source": [
    "model = clone(clf)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "_ = describe_model(y_test, y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.293\n",
      "average_odds_difference         0.325\n",
      "equal_opportunity_difference    0.531\n",
      "disparate_impact                18.818\n",
      "theil_index                     0.108\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "_ = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Grid itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.759\n",
      "Precision      0.627\n",
      "Recall         0.522\n",
      "F1             0.488\n"
     ]
    }
   ],
   "source": [
    "_ = describe_model(y_test, grid.predict(X_test), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.019\n",
      "average_odds_difference         0.019\n",
      "equal_opportunity_difference    0.026\n",
      "disparate_impact                10.277\n",
      "theil_index                     0.223\n"
     ]
    }
   ],
   "source": [
    "_ = describe_fairness(y_train, grid.predict(X_train), list(privileged_subset[0].keys()) ,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.450\n",
      "Precision      0.554\n",
      "Recall         0.564\n",
      "F1             0.447\n"
     ]
    }
   ],
   "source": [
    "model = clone(clf)\n",
    "model.fit(grid.transform(X_train), y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "_ = describe_model(y_test, y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.084\n",
      "average_odds_difference         0.064\n",
      "equal_opportunity_difference    0.054\n",
      "disparate_impact                1.116\n",
      "theil_index                     0.085\n"
     ]
    }
   ],
   "source": [
    "_ = describe_fairness(y_train, model.predict(X_train), list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Also Transforming test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.766\n",
      "Precision      0.662\n",
      "Recall         0.587\n",
      "F1             0.596\n"
     ]
    }
   ],
   "source": [
    "_ = describe_model(y_test, model.predict(grid.transform(X_test)), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.123\n",
      "average_odds_difference         0.100\n",
      "equal_opportunity_difference    0.141\n",
      "disparate_impact                3.928\n",
      "theil_index                     0.177\n"
     ]
    }
   ],
   "source": [
    "_ = describe_fairness(y_train, model.predict(grid.transform(X_train)), list(privileged_subset[0].keys()) ,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Runs cannot be done, because of the dataset already needs to be one hot encoded for the mitigation, making the `search_bias` function unnecessary and returning not viable resolutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils_fairness import create_aif360_standardDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create (un)privileged groups\n",
    "privileged_groups = [{key: 1 for key in list(privileged_subset[0].keys())}]\n",
    "unprivileged_groups = [{key: 0 for key in list(privileged_subset[0].keys())}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 605.8719525156314, L_x: 4089.307287970777,  L_y: 0.5649788796359236,  L_z: 0.000442105866442874\n",
      "step: 250, loss: 605.8719527432613, L_x: 4089.307287989528,  L_y: 0.564978879863366,  L_z: 0.000442105806862049\n",
      "step: 500, loss: 605.8719475746043, L_x: 4089.307287967263,  L_y: 0.5649788746949316,  L_z: 0.0004421057161778499\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          500     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.05872D+02    |proj g|=  2.78235D+01\n",
      "step: 750, loss: 559.2910323520119, L_x: 4088.5294761775235,  L_y: 0.5184057375902368,  L_z: 0.0004318659186486676\n",
      "step: 1000, loss: 559.291034705393, L_x: 4088.5294761868945,  L_y: 0.518405739943524,  L_z: 0.00043186608255237833\n",
      "\n",
      "At iterate    1    f=  5.59291D+02    |proj g|=  1.09570D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  500      1      2     11     0    10   1.096D+01   5.593D+02\n",
      "  F =   559.29103255898451     \n",
      "\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT        \n"
     ]
    }
   ],
   "source": [
    "TR = LFR(unprivileged_groups=unprivileged_groups,\n",
    "         privileged_groups=privileged_groups,\n",
    "         k=10, Ax=0.01, Ay=1000, Az=0,\n",
    "         verbose=1,\n",
    "         seed=random_state\n",
    ")\n",
    "\n",
    "TR = TR.fit(train_dataset, maxiter=5000, maxfun=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training data and align features\n",
    "train_dataset_lfr = TR.transform(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 37329}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = {}\n",
    "for i in train_dataset_lfr.labels.ravel():\n",
    "    cnt[i] = cnt.get(i, 0) + 1\n",
    "\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.826\n",
      "Precision      0.801\n",
      "Recall         0.680\n",
      "F1             0.710\n"
     ]
    }
   ],
   "source": [
    "model = clone(clf)\n",
    "model.fit(train_dataset.features, train_dataset.labels.ravel())\n",
    "y_pred = model.predict(test_dataset.features)\n",
    "\n",
    "_ = describe_model(test_dataset.labels.ravel(), y_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.294\n",
      "average_odds_difference         0.326\n",
      "equal_opportunity_difference    0.533\n",
      "disparate_impact                19.095\n",
      "theil_index                     0.108\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(train_dataset.features)\n",
    "_ = describe_fairness(df_train_bias[target], y_pred, list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric         Value               \n",
      "Accuracy       0.759\n",
      "Precision      0.380\n",
      "Recall         0.500\n",
      "F1             0.432\n"
     ]
    }
   ],
   "source": [
    "_ = describe_model(df_test_bias[target], [0]*len(df_test_bias[target]), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                          Value               \n",
      "statistical_parity_difference   0.000\n",
      "average_odds_difference         0.000\n",
      "equal_opportunity_difference    0.000\n",
      "disparate_impact                0.000\n",
      "theil_index                     0.229\n"
     ]
    }
   ],
   "source": [
    "_ = describe_fairness(df_train_bias[target], np.array([0]*len(df_train_bias)), list(privileged_subset[0].keys()), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disparate Impact Remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = train_dataset.feature_names.index('capital-gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:20<00:00,  8.08s/it]\n"
     ]
    }
   ],
   "source": [
    "fairness_metrics = []\n",
    "utility_metrics = []\n",
    "for level in tqdm(np.linspace(0, 1, 10)):\n",
    "    di = DisparateImpactRemover(repair_level=level)\n",
    "    train_repd = di.fit_transform(train_dataset)\n",
    "    test_repd = di.fit_transform(test_dataset)\n",
    "    \n",
    "    X_tr = train_repd.features # np.delete(train_repd.features, index, axis=1)\n",
    "    X_te = test_repd.features #np.delete(test_repd.features, index, axis=1)\n",
    "    y_tr = train_repd.labels.ravel()\n",
    "    \n",
    "    model = clone(clf)\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    utility_metrics.append(describe_model(test_repd.labels.ravel(), model.predict(X_te), verbose=False))\n",
    "    fairness_metrics.append(describe_fairness(df_train_bias[target], model.predict(X_tr), list(privileged_subset[0].keys()), verbose=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'statistical_parity_difference': 0.2940092562267429,\n",
       "  'average_odds_difference': 0.3263848052479457,\n",
       "  'equal_opportunity_difference': 0.5325510761059932,\n",
       "  'disparate_impact': 19.095289689901932,\n",
       "  'theil_index': 0.1077590833288912},\n",
       " {'statistical_parity_difference': 0.2926759922159685,\n",
       "  'average_odds_difference': 0.32400351074853,\n",
       "  'equal_opportunity_difference': 0.5288239686829213,\n",
       "  'disparate_impact': 18.60250658070242,\n",
       "  'theil_index': 0.10785454947161889},\n",
       " {'statistical_parity_difference': 0.29601781229946794,\n",
       "  'average_odds_difference': 0.3273713007937284,\n",
       "  'equal_opportunity_difference': 0.5331354249337793,\n",
       "  'disparate_impact': 18.92023897146681,\n",
       "  'theil_index': 0.10706475179598487},\n",
       " {'statistical_parity_difference': 0.2930458985007494,\n",
       "  'average_odds_difference': 0.324333673654631,\n",
       "  'equal_opportunity_difference': 0.5289796834135347,\n",
       "  'disparate_impact': 18.567530746486483,\n",
       "  'theil_index': 0.10789597007646609},\n",
       " {'statistical_parity_difference': 0.29331554449865205,\n",
       "  'average_odds_difference': 0.3242935481496774,\n",
       "  'equal_opportunity_difference': 0.5289311272072144,\n",
       "  'disparate_impact': 18.81505991323392,\n",
       "  'theil_index': 0.10763723963610193},\n",
       " {'statistical_parity_difference': 0.2933328646117791,\n",
       "  'average_odds_difference': 0.31997502616980295,\n",
       "  'equal_opportunity_difference': 0.5201541743268268,\n",
       "  'disparate_impact': 17.16745675281161,\n",
       "  'theil_index': 0.10696032232887571},\n",
       " {'statistical_parity_difference': 0.29282810948998655,\n",
       "  'average_odds_difference': 0.32411594896050416,\n",
       "  'equal_opportunity_difference': 0.5285125392216942,\n",
       "  'disparate_impact': 18.27405180071282,\n",
       "  'theil_index': 0.10806530490682205},\n",
       " {'statistical_parity_difference': 0.293310939582117,\n",
       "  'average_odds_difference': 0.32495685178376366,\n",
       "  'equal_opportunity_difference': 0.5299625280035362,\n",
       "  'disparate_impact': 18.583419443000675,\n",
       "  'theil_index': 0.10794042585394414},\n",
       " {'statistical_parity_difference': 0.2941072140553536,\n",
       "  'average_odds_difference': 0.3255107200598534,\n",
       "  'equal_opportunity_difference': 0.5298068132729227,\n",
       "  'disparate_impact': 18.688585017322637,\n",
       "  'theil_index': 0.10809451286437899},\n",
       " {'statistical_parity_difference': 0.29266217746636347,\n",
       "  'average_odds_difference': 0.3222527192998701,\n",
       "  'equal_opportunity_difference': 0.5248440341165952,\n",
       "  'disparate_impact': 17.939543713915157,\n",
       "  'theil_index': 0.10783597087983203}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'statistical_parity_difference': 0.2940092562267429,\n",
       " 'average_odds_difference': 0.3263848052479457,\n",
       " 'equal_opportunity_difference': 0.5325510761059932,\n",
       " 'disparate_impact': 19.095289689901932,\n",
       " 'theil_index': 0.1077590833288912}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index, max_disparate_impact_row = max(enumerate(fairness_metrics), key=lambda x: x[1]['disparate_impact'])\n",
    "max_disparate_impact_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.8263823560154698,\n",
       " 'Precision': 0.8009893116559623,\n",
       " 'Recall': 0.680496775358145,\n",
       " 'F1': 0.7095284659429854}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility_metrics[max_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
